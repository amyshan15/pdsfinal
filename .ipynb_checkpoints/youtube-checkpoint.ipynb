{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing YouTube Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Created by three former PayPal employees in 2005 and later acquired in 2006 by Google, YouTube has tranformed from a simple video hosting service into the world's largest entertainment platform. A community for creators everywhere, YouTube has proven able to support its creators financially as well through Google's targeted advertising program AdSense, and people are using that to quit their jobs and focus on their YouTube channels as a full-time career. In fact, in an age where anyone can pick up their phones and start a vlog, the question of what makes a YouTube channel successful is hotly debated. Today, we'll be looking to characterize different types of channels (popular, growing, declining) across several genres (lifestyle, food & travel, gaming, beauty & fashion) to get an idea of what being a successful YouTuber looks like.\n",
    "\n",
    "#### Q: What does a successful YouTube channel look like?\n",
    "\n",
    "To break this down even further, we're going to answer this question by carrying out the following steps:\n",
    "\n",
    "1. Dataset Assembly\n",
    "2. Feature engineering\n",
    "3. Model Training\n",
    "3. Cluster Visualization\n",
    "4. Analysis\n",
    "\n",
    "Without further ado, let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Assembly\n",
    "\n",
    "To assemble our dataset, we're going to query the YouTube Data API's search function for our genres (lifestyle, food & travel, gaming, beauty & fashion) and filter the data returned for our 3 types of channels. But in order to do that, we're have to first define what characterizes these types so we know how to filter the data for them.\n",
    "\n",
    "### Channel Types\n",
    "\n",
    "#### Popular\n",
    "\n",
    "A **popular** channel has popular videos (view count), a large following (subscriber count), and active community (comment section). In addition, consistency is also extremely important because it measures the ability of the channel to engage its followers so channels that post a few viral videos are not popular by our definition. Popular channels may not necessarily have the highest view count per video, but accumulate views through consistent content release and the community around them.\n",
    "\n",
    "#### Growing\n",
    "\n",
    "A **growing** channel is like a popular channel except it only started gaining traction recently so its community activity may not be as consistent. Many channels with growing view counts and subscriber counts exist on YouTube, but the key distinction for the growing channels we've defined is the consistency of its content release schedule. Like we mentioned earlier, channels only become popular if they engage their audience consistently and publish content on a regular basis so we'll be filtering for that when we identify growing channels.\n",
    "\n",
    "#### Declining\n",
    "\n",
    "A **declining** channel may have a large subscriber count, but its view count is falling steadily and its comment sections may be less active than they were before. In general, channels decline when they don't stick to content release schedules and fail to engage their audiences, but we're interested in knowing why certain channels that do publish content regularly still fail. That's why we'll focus on again on channels that publish content consistently to see what other features come into play here.\n",
    "\n",
    "Great! Now that we've defined the 3 types of channels we're looking for, assembling the dataset will be a much smoother process. However, it is also important to consider additional filters in order to guarantee that we answer our question above in the most meaningful way possible.\n",
    "\n",
    "### Sampling Bias\n",
    "\n",
    "To understand the motivation behind asking our question, consider music as a genre on YouTube. Vevo is a music video hosting service that partners with huge records labels like the Warner Music Group, and as a part of their contracts, Vevo helps artists like Eminem and Rihanna manage their YouTube channels. As we've defined above, channels like EminemVEVO and RihannaVEVO would be considered **popular** channels, but their success is largely derived from the artists' success in the music industry and other platforms like Spotify. \n",
    "\n",
    "Because of this, we're not extremely interested in investigating what makes these YouTube channels successful because we suspect that a big part of their success is independent of the YouTube channels themselves. That's why we're not considering music as a genre when we're assembling this dataset and why we're not looking into other genres like late night talk shows because most of them present the same confounding variables that influence the success of their channels.\n",
    "\n",
    "### YouTube Data API\n",
    "\n",
    "For querying the YouTube database, we'll be using the YouTube Data API. Here is a link to its official documentation: https://developers.google.com/youtube/v3/.\n",
    "\n",
    "More specifically, we're interested in using a method called **search: list**, which will allow us to query the database with parameters like keywords, location, etc. More information about this method can be found here: https://developers.google.com/youtube/v3/docs/search/list.\n",
    "\n",
    "We start by instantiating an object that establishes an authenticated connection to the YouTube Data Api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from httplib2 import Http\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "API_KEY = \"AIzaSyDI8cZyqHiXp1uh9zr5qPRKe4-bhhaPYUw\" # use your Google Developers Console API key\n",
    "\n",
    "def get_authenticated_service():\n",
    "    return build(API_SERVICE_NAME, API_VERSION, http=Http(), developerKey=API_KEY)\n",
    "\n",
    "client = get_authenticated_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this object to make requests to the YouTube Data API. Below, for example, we have a code snippet that gets 25 channels about ukuleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ukulele Teacher\n",
      "UC1HlihY-iNtOemAlYQq3GXQ\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"part\": \"snippet\",\n",
    "    \"maxResults\": \"25\",\n",
    "    \"q\": \"ukulele\",\n",
    "    \"type\": \"channel\"\n",
    "}\n",
    "\n",
    "response = client.search().list(**params).execute()\n",
    "print(response['items'][0]['snippet']['title'])\n",
    "print(response['items'][0]['id']['channelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the demo code above to query for up to 50 (limit) channels related to each of our topics and add them to a pandas dataframe where we store our dataset. To ensure we obtain as much data for preprocessing as possible, we're considering 3 orderings: relevance, video count, and view count. This will give us something closer to 700 channels rather than 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>UCtE1l7hJ1helcsyxoquNDvQ</td>\n",
       "      <td>NBO FITNESS</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>UCrF6sYzdIgo64yi5GlcSsDw</td>\n",
       "      <td>Pain &amp; Gain Fitness</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>Management: Christian Torres Video Edit: Denis...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                 Channel Name     Created  \\\n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg               Batman Fitness  2016-11-06   \n",
       "690  UCtE1l7hJ1helcsyxoquNDvQ                  NBO FITNESS  2012-06-29   \n",
       "691  UCrF6sYzdIgo64yi5GlcSsDw          Pain & Gain Fitness  2011-03-28   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A  Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                 ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness  \n",
       "690  YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...  Fitness  \n",
       "691  Management: Christian Torres Video Edit: Denis...  Fitness  \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness  \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataset(topics, n=50):\n",
    "    dataset = {\n",
    "        'Channel ID': [],\n",
    "        'Channel Name': [],\n",
    "        'Description': [],\n",
    "        'Created': [],\n",
    "        'Genre': []\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"maxResults\": n,\n",
    "        \"relevanceLanguage\": \"en\",\n",
    "        \"type\": \"channel\"\n",
    "    }\n",
    "\n",
    "    channels = set()\n",
    "    orders = ['relevance', 'viewCount', 'videoCount']\n",
    "    \n",
    "    for topic in topics:\n",
    "        params['q'] = topic\n",
    "        for order in orders:\n",
    "            params['order'] = order\n",
    "            response = client.search().list(**params).execute()\n",
    "\n",
    "            for channel in response['items']:\n",
    "                channel_id = channel['id']['channelId']\n",
    "                channel_name = channel['snippet']['title']\n",
    "                channel_description = channel['snippet']['description']\n",
    "                channel_created = channel['snippet']['publishedAt']\n",
    "                channel_created = channel_created[:channel_created.find('T')]\n",
    "\n",
    "                if channel_id not in channels:\n",
    "                    dataset['Channel ID'].append(channel_id)\n",
    "                    dataset['Channel Name'].append(channel_name)\n",
    "                    dataset['Description'].append(channel_description)\n",
    "                    dataset['Created'].append(channel_created)\n",
    "                    dataset['Genre'].append(topic)\n",
    "                    \n",
    "                    channels.add(channel_id)\n",
    "\n",
    "    return pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "topics = ['Vlog', 'Food', 'Gaming', 'Beauty', 'Fashion', 'Fitness']\n",
    "init_dataset = create_dataset(topics)\n",
    "init_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extension\n",
    "\n",
    "Awesome! We have now assembled a dataset around channels in the topics that we care about, but the dataset is lacking in features. Ideally, we would have additional information about the channel so we can characterize them into the 3 types we defined earlier.\n",
    "\n",
    "Below, we will extend our dataset to include the following features about each channel:\n",
    "- view count\n",
    "- subscriber count\n",
    "- video count\n",
    "\n",
    "We'll take these simple channel statistics and engineering some features like Views/Subscriber, which will give us an idea of how much each subscriber to the channel is contributing to the views on that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>UCFoe1jpBJZB9sPUDoLMykGA</td>\n",
       "      <td>Lumowell - fitness | Español</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Wellness y fitness evolucionado. Videos para m...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>440640</td>\n",
       "      <td>596.265223</td>\n",
       "      <td>739</td>\n",
       "      <td>39395881</td>\n",
       "      <td>89.406048</td>\n",
       "      <td>53309.717185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>170</td>\n",
       "      <td>0.242511</td>\n",
       "      <td>701</td>\n",
       "      <td>104665</td>\n",
       "      <td>615.676471</td>\n",
       "      <td>149.308131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>897</td>\n",
       "      <td>1.270538</td>\n",
       "      <td>706</td>\n",
       "      <td>217912</td>\n",
       "      <td>242.934225</td>\n",
       "      <td>308.657224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>95484</td>\n",
       "      <td>162.387755</td>\n",
       "      <td>588</td>\n",
       "      <td>18526473</td>\n",
       "      <td>194.026989</td>\n",
       "      <td>31507.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>56842</td>\n",
       "      <td>99.374126</td>\n",
       "      <td>572</td>\n",
       "      <td>12854403</td>\n",
       "      <td>226.142694</td>\n",
       "      <td>22472.732517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name     Created  \\\n",
       "687  UCFoe1jpBJZB9sPUDoLMykGA  Lumowell - fitness | Español  2014-12-23   \n",
       "688  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  2010-10-18   \n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg                Batman Fitness  2016-11-06   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A   Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                  ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "687  Wellness y fitness evolucionado. Videos para m...  Fitness   \n",
       "688  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness   \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness   \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "687            440640        596.265223          739    39395881   \n",
       "688               170          0.242511          701      104665   \n",
       "689               897          1.270538          706      217912   \n",
       "692             95484        162.387755          588    18526473   \n",
       "693             56842         99.374126          572    12854403   \n",
       "\n",
       "     Views/Subscriber   Views/Video  \n",
       "687         89.406048  53309.717185  \n",
       "688        615.676471    149.308131  \n",
       "689        242.934225    308.657224  \n",
       "692        194.026989  31507.607143  \n",
       "693        226.142694  22472.732517  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_channel_stats(channel, params):\n",
    "    params['id'] = channel\n",
    "    res = client.channels().list(**params).execute()\n",
    "    return res['items'][0]['statistics']\n",
    "\n",
    "def extend_features(dataset):\n",
    "    params = {'part': 'statistics'}\n",
    "    extended = {\n",
    "        'Channel ID': [],\n",
    "        'View Count': [],\n",
    "        'Subscriber Count': [],\n",
    "        'Video Count': [],\n",
    "        'Views/Subscriber': [],\n",
    "        'Views/Video': [],\n",
    "        'Subscriber/Video': []\n",
    "    }\n",
    "        \n",
    "    for channel_id in dataset['Channel ID']:\n",
    "        channel_stats = get_channel_stats(channel_id, params)\n",
    "                \n",
    "        viewCount = int(channel_stats['viewCount'])\n",
    "        subscriberCount = int(channel_stats['subscriberCount'])\n",
    "        videoCount = int(channel_stats['videoCount'])\n",
    "        \n",
    "        if videoCount == 0 or viewCount == 0 or subscriberCount == 0:\n",
    "            continue\n",
    "        \n",
    "        extended['Channel ID'].append(channel_id)\n",
    "        extended['View Count'].append(viewCount)\n",
    "        extended['Subscriber Count'].append(subscriberCount)\n",
    "        extended['Video Count'].append(videoCount)\n",
    "        extended['Views/Subscriber'].append(viewCount/subscriberCount)\n",
    "        extended['Views/Video'].append(viewCount/videoCount)\n",
    "        extended['Subscriber/Video'].append(subscriberCount/videoCount)\n",
    "    \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended).set_index('Channel ID')\n",
    "    return dataset.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "    \n",
    "channel_features_dataset = extend_features(init_dataset)\n",
    "channel_features_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Features\n",
    "\n",
    "#### 1. Community Activity\n",
    "\n",
    "Earlier, we identified a channel's community as an important metric in measuring its popularity, and a channel's comment section best reflects this. However, the YouTube API does not return an accurate comment count per channel, so we will query each channels last 20 videos to get an idea of how active the channel's comment sections for each of those videos are.\n",
    "\n",
    "#### 2. Content Consistency\n",
    "\n",
    "Additionally, our sampling targets consistent uploaders because we assume that the uploader is active so we will use these videos to look for how far apart the dates between uploads are on average. If this average is greater than a week, we can conclude that the channel is not a consistent uploader.\n",
    "\n",
    "#### 3. Growth Rate\n",
    "\n",
    "To also characterize whether a channel is growing or declining, we will use the channel's percentage change in view counts across these videos. For example, a percent change of over 20% and under -20% might be labeled as growing and declining respectively, and anything between that will be labeled as a possibly popular channel.\n",
    "\n",
    "#### 4. Favorability\n",
    "\n",
    "Lastly, each video has a statistics on the number of likes and dislikes, which is the only venue through which users can give direct binary feedback on the content uploaders post. Other methods for classifying how people feel rely on analyzing the sentiment of the comments section via NLP methods, and due to high variability we will not be covering that in this notebook. Thus, the higher the ratio of likes to dislikes, the more favorable these videos are as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sec_to_day = lambda x: np.round(x/86400, 1)\n",
    "\n",
    "def get_video_stats(video, params):\n",
    "    try:\n",
    "        params['id'] = video\n",
    "        res = client.videos().list(**params).execute()\n",
    "        stats = res['items'][0]['statistics']\n",
    "        stats['publishedAt'] = res['items'][0]['snippet']['publishedAt']\n",
    "        return (True, stats)\n",
    "    except:\n",
    "        return (False, None)\n",
    "    \n",
    "def get_channel_videos(channel, n=50):\n",
    "    channel_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'id' : channel\n",
    "    }\n",
    "    res = client.channels().list(**channel_params).execute()\n",
    "    upload_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    playlist_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'playlistId' : upload_id,\n",
    "        'maxResults' : n\n",
    "    }\n",
    "    uploads = client.playlistItems().list(**playlist_params).execute()\n",
    "    return uploads['items']\n",
    "\n",
    "def calc_channel_video_stats(dates, views, likes, dislikes, comments):\n",
    "    video_stats = dict()\n",
    "    \n",
    "    views, likes, dislikes, comments = np.array(views), np.array(likes), np.array(dislikes), np.array(comments)\n",
    "    dates = list(map(lambda x: dateutil.parser.parse(x), dates))\n",
    "        \n",
    "    # average views per upload\n",
    "    video_stats['Views/Upload'] = np.mean(views)\n",
    "    # average likes per upload\n",
    "    video_stats['Likes/Upload'] = np.mean(likes)\n",
    "    # average dislikes per upload\n",
    "    video_stats['Dislikes/Upload'] = np.mean(dislikes)\n",
    "    # average comments per upload\n",
    "    video_stats['Comments/Upload'] = np.mean(comments)\n",
    "    # like to views ratio\n",
    "    video_stats['Likes/View'] = np.mean(likes/views)*100\n",
    "    # dislikes to views ratio\n",
    "    video_stats['Dislikes/View'] = np.mean(dislikes/views)*100\n",
    "    # comments to views ratio\n",
    "    video_stats['Comments/View'] = np.mean(comments/views)*100\n",
    "    # upload frequency\n",
    "    time_diff = (dates[-1] - dates[0]).total_seconds()\n",
    "    video_stats['Days/Upload'] = sec_to_day(time_diff / len(dates))\n",
    "\n",
    "    upload_days = list(map(lambda x: sec_to_day((x - dates[0]).total_seconds()), dates))\n",
    "    m, b, r, p, err = stats.linregress(upload_days, views)\n",
    "    # growth rate (views)\n",
    "    video_stats['Growth Rate'] = (m / views[0]) * 100\n",
    "    \n",
    "    return video_stats\n",
    "    \n",
    "def get_channel_video_stats(channel):\n",
    "    published_dates = []\n",
    "    view_counts = []\n",
    "    like_counts = []\n",
    "    dislike_counts = []\n",
    "    comment_counts = []\n",
    "    \n",
    "    video_params = { 'part': 'snippet,statistics' }\n",
    "    \n",
    "    channel_videos = get_channel_videos(channel)\n",
    "    \n",
    "    if len(channel_videos) == 0:\n",
    "        return None\n",
    "        \n",
    "    for i in range(len(channel_videos)-1, -1, -1):\n",
    "        video_info = channel_videos[i]\n",
    "        video_id = video_info['contentDetails']['videoId']\n",
    "        \n",
    "        success, video_stats = get_video_stats(video_id, video_params)\n",
    "\n",
    "        # publishedAt, viewCount, likeCount, dislikeCount, commentCount\n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        published_dates.append(video_stats['publishedAt'])\n",
    "        \n",
    "        view_counts.append(int(video_stats['viewCount']) if 'viewCount' in video_stats else 0)\n",
    "        like_counts.append(int(video_stats['likeCount']) if 'likeCount' in video_stats else 0)\n",
    "        dislike_counts.append(int(video_stats['dislikeCount']) if 'dislikeCount' in video_stats else 0)\n",
    "        comment_counts.append(int(video_stats['commentCount']) if 'commentCount' in video_stats else 0)\n",
    "                        \n",
    "    return calc_channel_video_stats(published_dates, view_counts, like_counts, dislike_counts, comment_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:106: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = r_num / ssxm\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:116: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "      <th>Comments/Upload</th>\n",
       "      <th>Comments/View</th>\n",
       "      <th>Days/Upload</th>\n",
       "      <th>Dislikes/Upload</th>\n",
       "      <th>Dislikes/View</th>\n",
       "      <th>Growth Rate</th>\n",
       "      <th>Likes/Upload</th>\n",
       "      <th>Likes/View</th>\n",
       "      <th>Views/Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>UCFoe1jpBJZB9sPUDoLMykGA</td>\n",
       "      <td>Lumowell - fitness | Español</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Wellness y fitness evolucionado. Videos para m...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>440108</td>\n",
       "      <td>595.545332</td>\n",
       "      <td>739</td>\n",
       "      <td>39335272</td>\n",
       "      <td>89.376408</td>\n",
       "      <td>53227.702300</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.093251</td>\n",
       "      <td>-1.067616</td>\n",
       "      <td>465.14</td>\n",
       "      <td>7.216093</td>\n",
       "      <td>6642.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>170</td>\n",
       "      <td>0.242511</td>\n",
       "      <td>701</td>\n",
       "      <td>104568</td>\n",
       "      <td>615.105882</td>\n",
       "      <td>149.169757</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.273421</td>\n",
       "      <td>47.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>891</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>704</td>\n",
       "      <td>216151</td>\n",
       "      <td>242.593715</td>\n",
       "      <td>307.032670</td>\n",
       "      <td>14.58</td>\n",
       "      <td>6.234693</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.06</td>\n",
       "      <td>2.180904</td>\n",
       "      <td>-6.571514</td>\n",
       "      <td>15.96</td>\n",
       "      <td>7.857068</td>\n",
       "      <td>253.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>95118</td>\n",
       "      <td>162.040886</td>\n",
       "      <td>587</td>\n",
       "      <td>18476925</td>\n",
       "      <td>194.252665</td>\n",
       "      <td>31476.873935</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15.44</td>\n",
       "      <td>0.175641</td>\n",
       "      <td>-591.460505</td>\n",
       "      <td>290.94</td>\n",
       "      <td>2.322659</td>\n",
       "      <td>20110.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>56812</td>\n",
       "      <td>99.321678</td>\n",
       "      <td>572</td>\n",
       "      <td>12849332</td>\n",
       "      <td>226.172851</td>\n",
       "      <td>22463.867133</td>\n",
       "      <td>28.80</td>\n",
       "      <td>1.893966</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>-1.409487</td>\n",
       "      <td>151.20</td>\n",
       "      <td>6.117708</td>\n",
       "      <td>5736.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name     Created  \\\n",
       "687  UCFoe1jpBJZB9sPUDoLMykGA  Lumowell - fitness | Español  2014-12-23   \n",
       "688  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  2010-10-18   \n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg                Batman Fitness  2016-11-06   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A   Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                  ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "687  Wellness y fitness evolucionado. Videos para m...  Fitness   \n",
       "688  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness   \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness   \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "687            440108        595.545332          739    39335272   \n",
       "688               170          0.242511          701      104568   \n",
       "689               891          1.265625          704      216151   \n",
       "692             95118        162.040886          587    18476925   \n",
       "693             56812         99.321678          572    12849332   \n",
       "\n",
       "     Views/Subscriber   Views/Video  Comments/Upload  Comments/View  \\\n",
       "687         89.376408  53227.702300             6.82       0.100957   \n",
       "688        615.105882    149.169757             0.00       0.000000   \n",
       "689        242.593715    307.032670            14.58       6.234693   \n",
       "692        194.252665  31476.873935             4.44       0.158249   \n",
       "693        226.172851  22463.867133            28.80       1.893966   \n",
       "\n",
       "     Days/Upload  Dislikes/Upload  Dislikes/View  Growth Rate  Likes/Upload  \\\n",
       "687          1.2             5.96       0.093251    -1.067616        465.14   \n",
       "688          5.0             0.00       0.000000     0.107155          0.14   \n",
       "689          0.3             5.06       2.180904    -6.571514         15.96   \n",
       "692          1.3            15.44       0.175641  -591.460505        290.94   \n",
       "693          6.2             4.86       0.342653    -1.409487        151.20   \n",
       "\n",
       "     Likes/View  Views/Upload  \n",
       "687    7.216093       6642.84  \n",
       "688    0.273421         47.76  \n",
       "689    7.857068        253.56  \n",
       "692    2.322659      20110.36  \n",
       "693    6.117708       5736.02  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Channels with no videos returned are filtered out (ex: UCOpNcN46UbXVtpKMrmU4Abg)\n",
    "\n",
    "def extend_video_features(data):\n",
    "    extended_video = { 'Channel ID': [] }\n",
    "        \n",
    "    for channel_id in data['Channel ID']:            \n",
    "        channel_video_stats = get_channel_video_stats(channel_id)\n",
    "        \n",
    "        if channel_video_stats == None:\n",
    "            continue\n",
    "                    \n",
    "        extended_video['Channel ID'].append(channel_id)\n",
    "        for video_stat in channel_video_stats:\n",
    "            if video_stat not in extended_video:\n",
    "                extended_video[video_stat] = []\n",
    "            extended_video[video_stat].append(channel_video_stats[video_stat])\n",
    "                                        \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended_video).set_index('Channel ID')\n",
    "    return data.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "\n",
    "dataset = extend_video_features(channel_features_dataset)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "\n",
    "We now have 15 features on 700 channels on its most recent 50 videos that we'll store in a csv file \"youtube-data.csv\", and we're ready to extract the important features and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('youtube-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Now that we have all our assembled dataset, we need to apply some normalization methods to ensure that our KMeans++ clustering can give us the most meaningful results possible. To do so, we will apply feature scaling to bring the variance of our clusters closer together and apply kernel PCA as well to increase the dimensionality of our data so PCA can identify non-linear principal components.\n",
    "\n",
    "#### Feature Normalization\n",
    "On of the most common ways to standardize data across a dimension is to reduce the dimension to zero mean and unit variance. Let's apply the formula below for each feature dimension and see how our data changes. \n",
    "\n",
    "<center>$X^{(m)} = \\frac{X^{(m)} - \\overline{X^{(m)}}}{\\sigma}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "      <th>Comments/Upload</th>\n",
       "      <th>Comments/View</th>\n",
       "      <th>Days/Upload</th>\n",
       "      <th>Dislikes/Upload</th>\n",
       "      <th>Dislikes/View</th>\n",
       "      <th>Growth Rate</th>\n",
       "      <th>Likes/Upload</th>\n",
       "      <th>Likes/View</th>\n",
       "      <th>Views/Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>UCjKr2Ro-5X0BM6UptvhWvEw</td>\n",
       "      <td>The Ultimate Fashion History</td>\n",
       "      <td>10/26/12</td>\n",
       "      <td>FASHION HISTORY LIKE YOU'VE NEVER LEARNED IT B...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.431295</td>\n",
       "      <td>-0.341956</td>\n",
       "      <td>-0.448291</td>\n",
       "      <td>-0.311062</td>\n",
       "      <td>-0.629982</td>\n",
       "      <td>-0.311746</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>-0.234135</td>\n",
       "      <td>-0.253131</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>-0.326700</td>\n",
       "      <td>0.398713</td>\n",
       "      <td>-0.236878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>UCS-HyxHT3A_PLXC8zlX73Yw</td>\n",
       "      <td>Fashion Television</td>\n",
       "      <td>11/10/14</td>\n",
       "      <td>Fashion Television is considered the leading a...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.435253</td>\n",
       "      <td>-0.363157</td>\n",
       "      <td>-0.143750</td>\n",
       "      <td>-0.306632</td>\n",
       "      <td>0.783178</td>\n",
       "      <td>-0.318565</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.597007</td>\n",
       "      <td>-0.235434</td>\n",
       "      <td>-0.287314</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>-0.331377</td>\n",
       "      <td>-0.922151</td>\n",
       "      <td>-0.239402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>UCoc8tpGCY1wrp8pV7mI0scA</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>3/7/07</td>\n",
       "      <td>Welcome to H&amp;M's official YouTube page. Explor...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.294380</td>\n",
       "      <td>-0.270066</td>\n",
       "      <td>-0.286767</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>1.182617</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>0.367722</td>\n",
       "      <td>-0.065151</td>\n",
       "      <td>-0.105284</td>\n",
       "      <td>0.475871</td>\n",
       "      <td>-0.289295</td>\n",
       "      <td>-1.015866</td>\n",
       "      <td>0.880160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>UCkkVe_1wVVhT_w_BU6CKgXw</td>\n",
       "      <td>Fashion9tv</td>\n",
       "      <td>8/10/16</td>\n",
       "      <td>fashion9tv channel is reference channel for ge...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.416403</td>\n",
       "      <td>-0.362802</td>\n",
       "      <td>1.041181</td>\n",
       "      <td>-0.286283</td>\n",
       "      <td>0.387297</td>\n",
       "      <td>-0.318919</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.708859</td>\n",
       "      <td>-0.235288</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>-0.010982</td>\n",
       "      <td>-0.331367</td>\n",
       "      <td>-1.258717</td>\n",
       "      <td>-0.239284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>10/18/10</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>-0.439641</td>\n",
       "      <td>-0.364862</td>\n",
       "      <td>-0.204322</td>\n",
       "      <td>-0.313200</td>\n",
       "      <td>1.446982</td>\n",
       "      <td>-0.323333</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.051725</td>\n",
       "      <td>-0.235467</td>\n",
       "      <td>-0.414546</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>-0.331404</td>\n",
       "      <td>-1.356894</td>\n",
       "      <td>-0.239401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name   Created  \\\n",
       "604  UCjKr2Ro-5X0BM6UptvhWvEw  The Ultimate Fashion History  10/26/12   \n",
       "605  UCS-HyxHT3A_PLXC8zlX73Yw            Fashion Television  11/10/14   \n",
       "606  UCoc8tpGCY1wrp8pV7mI0scA                           H&M    3/7/07   \n",
       "607  UCkkVe_1wVVhT_w_BU6CKgXw                    Fashion9tv   8/10/16   \n",
       "608  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  10/18/10   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "604  FASHION HISTORY LIKE YOU'VE NEVER LEARNED IT B...  Fashion   \n",
       "605  Fashion Television is considered the leading a...  Fashion   \n",
       "606  Welcome to H&M's official YouTube page. Explor...  Fashion   \n",
       "607  fashion9tv channel is reference channel for ge...  Fashion   \n",
       "608  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "604         -0.431295         -0.341956    -0.448291   -0.311062   \n",
       "605         -0.435253         -0.363157    -0.143750   -0.306632   \n",
       "606         -0.294380         -0.270066    -0.286767   -0.043644   \n",
       "607         -0.416403         -0.362802     1.041181   -0.286283   \n",
       "608         -0.439641         -0.364862    -0.204322   -0.313200   \n",
       "\n",
       "     Views/Subscriber  Views/Video  Comments/Upload  Comments/View  \\\n",
       "604         -0.629982    -0.311746        -0.272409      -0.563164   \n",
       "605          0.783178    -0.318565        -0.272409      -0.563164   \n",
       "606          1.182617     0.005803        -0.272409      -0.563164   \n",
       "607          0.387297    -0.318919        -0.272409      -0.563164   \n",
       "608          1.446982    -0.323333        -0.272409      -0.563164   \n",
       "\n",
       "     Days/Upload  Dislikes/Upload  Dislikes/View  Growth Rate  Likes/Upload  \\\n",
       "604     0.144017        -0.234135      -0.253131    -0.004679     -0.326700   \n",
       "605    -0.597007        -0.235434      -0.287314     0.001706     -0.331377   \n",
       "606     0.367722        -0.065151      -0.105284     0.475871     -0.289295   \n",
       "607    -0.708859        -0.235288       0.016218    -0.010982     -0.331367   \n",
       "608    -0.051725        -0.235467      -0.414546     0.002601     -0.331404   \n",
       "\n",
       "     Likes/View  Views/Upload  \n",
       "604    0.398713     -0.236878  \n",
       "605   -0.922151     -0.239402  \n",
       "606   -1.015866      0.880160  \n",
       "607   -1.258717     -0.239284  \n",
       "608   -1.356894     -0.239401  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data = pd.read_csv('youtube-data.csv')\n",
    "\n",
    "dataset = orig_data.drop(['Unnamed: 0'], axis=1)\n",
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "dataset = dataset.dropna(axis=0, how=\"any\")\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "def standardize_features(X):\n",
    "    return (X - np.mean(X)) / np.std(X)\n",
    "\n",
    "def normalize_data(data):\n",
    "    result = data.copy(deep=True)\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == object:\n",
    "            continue\n",
    "        result[column] = standardize_features(data[column])\n",
    "    return result\n",
    "\n",
    "norm_dataset = normalize_data(dataset)\n",
    "norm_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel PCA\n",
    "\n",
    "Next, we will apply a Gaussian RBF (Radial Basis Function) kernel to map our data into a higher dimensional space so we can identify a potentially non-linear lower dimensional subspace for our principal components. This is done by applying the function below to each pair of feature vectors.\n",
    "\n",
    "<center>$K(x,y) = exp(-\\frac{||x-y||^2}{2\\sigma^2})$</center>\n",
    "\n",
    "Additionally, we'll also apply a median distance trick and use that as the standard deviation across our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calc_median_dist(X):\n",
    "    dists = []\n",
    "    n,m = X.shape\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dist = np.sqrt(np.sum((X[i,:]-X[j,:])**2))\n",
    "            dists.append(dist)\n",
    "    return np.median(dists)\n",
    "\n",
    "def kernel_PCA(data, n=6):\n",
    "    num_data = data.drop(['Channel ID', 'Channel Name', 'Created', 'Description', 'Genre'], axis=1)\n",
    "    num_data = num_data.as_matrix()\n",
    "    \n",
    "    median_dist = calc_median_dist(num_data)\n",
    "    gamma = 1/(2*median_dist**2)\n",
    "    rbf = np.exp(-gamma * (np.sum(num_data**2, axis=-1)[:,None] + np.sum(num_data**2, axis=-1)[None,:] - 2*np.dot(num_data, num_data.T)))\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca.fit_transform(rbf)\n",
    "    \n",
    "kernel_data = kernel_PCA(norm_dataset)\n",
    "print(kernel_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have transformed our dataset into several potentially non-linear principal components, we will train a clustering model to see what major clusters these channels form.\n",
    "\n",
    "For this part, we chose the KMeans++ model because we think that similar channels (popular, growing, declining) should be close in distance in the project feature space (ie. share similar properties based on these identified metrics). In addition, we initially choose to train on $k=4$ clusters because we wanted an additional bucket for channels we cannot successfully label as one of our 3 types. \n",
    "\n",
    "We will perform tuning on hyperparameter $\\text{k}$ later when introduce our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From dzq homework 5\n",
    "import math\n",
    "\n",
    "def distance_matrix(X):\n",
    "    m,n = X.shape\n",
    "    M = np.zeros((m,m))\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            M[i,j] = np.sum((X[i]-X[j])**2)\n",
    "    return M\n",
    "\n",
    "class KMeans:\n",
    "    def init_centers(self, X, k):\n",
    "        centers = []\n",
    "        m = X.shape[0]\n",
    "        M = distance_matrix(X)\n",
    "        pos = np.arange(len(X))\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                center = X[np.random.choice(pos)]\n",
    "            else:\n",
    "                # Calculate probabilities\n",
    "                probs = []\n",
    "                for x in range(m):\n",
    "                    # Calculate each vector's probability\n",
    "                    sub_probs = []\n",
    "                    for y in range(m):\n",
    "                        sub_prob = []\n",
    "                        for center in centers:\n",
    "                            dist_to_center = np.sum((X[y]-center)**2)\n",
    "                            sub_prob.append(dist_to_center)\n",
    "                        val = np.min(sub_prob)\n",
    "                        sub_probs.append(val)\n",
    "                    \n",
    "                    num = sub_probs[x]\n",
    "                    denom = np.sum(sub_probs)\n",
    "                    \n",
    "                    prob = num/denom\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "                center = X[np.random.choice(pos, p=probs)]\n",
    "                \n",
    "            centers.append(center)\n",
    "            \n",
    "        centers = np.array(centers)\n",
    "        return centers\n",
    "        \n",
    "    def assign_clusters(self, X, centers):\n",
    "        m,k = X.shape[0], len(centers) \n",
    "        clusters = np.zeros((m,k))\n",
    "        for i in range(m):\n",
    "            probs = []\n",
    "            for j in range(k):\n",
    "                dist = np.sum((X[i]-centers[j])**2)\n",
    "                probs.append(dist)\n",
    "            y = np.argmin(probs)\n",
    "            clusters[i,y] = 1\n",
    "        return clusters\n",
    "    \n",
    "    def compute_means(self, X, y):\n",
    "        m, n, k = X.shape[0], X.shape[1], y.shape[1]\n",
    "        centers = np.zeros((k,n))\n",
    "        \n",
    "        for j in range(k):\n",
    "            cluster = np.zeros(n)\n",
    "            num_cluster = 0\n",
    "            for i in range(m):\n",
    "                if y[i,j] == 1:\n",
    "                    num_cluster += 1\n",
    "                    cluster = cluster + X[i]\n",
    "            center = cluster / num_cluster\n",
    "            centers[j,:] = center\n",
    "            \n",
    "        return centers    \n",
    "    \n",
    "    def train(self, X, centers, niters=500):\n",
    "        for i in range(niters):\n",
    "            clusters = self.assign_clusters(X, centers)\n",
    "            centers = self.compute_means(X, clusters)\n",
    "                    \n",
    "        return (clusters, centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running KMeans++, we can see the size of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  364\n",
      "Cluster 1:  58\n",
      "Cluster 2:  85\n",
      "Cluster 3:  102\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "KM = KMeans()\n",
    "mu = KM.init_centers(kernel_data, k)\n",
    "(labels, centers) = KM.train(kernel_data, mu)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d: \" % i, len(np.where(labels[:,i]==1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what channels are in our largest cluster, cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57                                    Adam Saleh Fashion\n",
       "66                                       RawBeautyKristi\n",
       "70                                       Fashion Diaries\n",
       "72                                    Inner Beauty Bybel\n",
       "74                                  The Life Of Us Vlogs\n",
       "76                                     TheGamingBritShow\n",
       "79                                      Gaming Historian\n",
       "82                                          ilie's vlogs\n",
       "83                            Best Ever Food Review Show\n",
       "84                                        Sascha Fitness\n",
       "87                                     Britpoplife Vlogs\n",
       "96                                       Laura Lee Vlogs\n",
       "97                                             UIC Vlogs\n",
       "100                        ERNEST DIFT - THE FITNESS BOY\n",
       "104                                               Anil B\n",
       "117                                    Samantha Ravndahl\n",
       "125                                            Lù Gaming\n",
       "130                                     The Food Emperor\n",
       "133                                    VitruvianPhysique\n",
       "135                                         Dobbs Gaming\n",
       "139                                        Fashion Laura\n",
       "140                             Justine Leconte officiel\n",
       "143                                       Vlog Creations\n",
       "145                                           다영 DAYEONG\n",
       "147                                              BenDeen\n",
       "154                                      Thefoodreviewer\n",
       "155                                        Nassim Sahili\n",
       "157                               Linkin Simpson's vlogs\n",
       "159                                    HappyConsoleGamer\n",
       "162                                        Beauty Tricks\n",
       "                             ...                        \n",
       "577                                          Gaming Blog\n",
       "578                                           Fitness.ee\n",
       "579                                         Time Fitness\n",
       "580                                     The Food Channel\n",
       "581                  WILLITARY FITNESS! FIT FUN AT HOME!\n",
       "582                                    BARÁTOK Blog Vlog\n",
       "583                              British Fashion Council\n",
       "584                              Fashion And Accessories\n",
       "585                                  U.S. Forces Fitness\n",
       "586                                       Gorilla Gaming\n",
       "587                          Style and fashion by bassem\n",
       "588                               Moda 2017 Fashion 2018\n",
       "589                                   Lakmé Fashion Week\n",
       "591                                            HW Beauty\n",
       "592                                      Beauty at Tesco\n",
       "593                               Latest Fashion Designs\n",
       "594                                     iOS Gaming World\n",
       "595                                          Fashion One\n",
       "596                                     Heath and Beauty\n",
       "597                                    Fly Dance Fitness\n",
       "598                              Premier Fitness Systems\n",
       "599                                 GU | Gaming-Universe\n",
       "600                                Princess Fashion Show\n",
       "601                                        ID Fashion TV\n",
       "602                                         Steves vlogs\n",
       "603    Food and Agriculture Organization of the Unite...\n",
       "604                         The Ultimate Fashion History\n",
       "605                                   Fashion Television\n",
       "607                                           Fashion9tv\n",
       "608                                    Fitness Incentive\n",
       "Name: Channel Name, Length: 364, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Channel Name\"][labels[:,0] == 1] # Cluster 0 (364 channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters\n",
    "\n",
    "In this section, we will consider $k$ that will generate different cluster labels for each channel. Then, we will calculate an error using cross entropy on a curated test dataset and minimize this our objective funciton to obtain the optimal hyperparameter.\n",
    "\n",
    "#### Test Data\n",
    "\n",
    "Our test dataset was manually assembled by searching for popular YouTube channels online, and filtering for channels that are not already in our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCAW-NpUFkMyCNrvRSSGIvDQ\n",
      "UC1uvf8YdxSVzthF45kotmJQ\n",
      "UCbTVTephX30ZhQF5zwFppBg\n",
      "UCS5Oz6CHmeoF7vSad0qqXfw\n",
      "UCpGdL9Sn3Q5YWUH2DVUW1Ug\n",
      "UCJQL1Fai-9GlVunsbP4x8Pg\n",
      "UCRIZtPl9nb9RiXc9btSTQNw\n",
      "UCNbngWUqL2eqRw12yAwcICg\n",
      "UC6S5a3MQtr_PSWZxysXkOCg\n",
      "UCffs63OaN2nh-6StR6hzfiQ\n",
      "UCAW-NpUFkMyCNrvRSSGIvDQ\n",
      "UC1uvf8YdxSVzthF45kotmJQ\n",
      "UCbTVTephX30ZhQF5zwFppBg\n",
      "UCS5Oz6CHmeoF7vSad0qqXfw\n",
      "UCpGdL9Sn3Q5YWUH2DVUW1Ug\n",
      "UC5zSySQab9SA6Wz569WDgqw\n",
      "UCgWfS_47YPVbKx5EK4FLm4A\n",
      "UCo5zIpjl2OQkYatd8R0bDaw\n",
      "UC-BaXc1TU9i0XSguq9mZwdg\n",
      "UC48DOiEvCDu3sThBijwkQ1A\n",
      "UCXIJ2-RSIGn53HA-x9RDevA\n",
      "UCuA6Ht35K326kBTPTXaWj3g\n",
      "UCgBc9iNvvjWDInV6fBeTGXQ\n",
      "UCuY1W4AwhhgkB6rsJBtltUA\n",
      "UCMTXToEZ6VT5k9GOCFNYjWA\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kernel_PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-6cdfdd1eb0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_channel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mtest_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtest_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kernel_PCA' is not defined"
     ]
    }
   ],
   "source": [
    "test_channel_ids = {\n",
    "    \"Vlog\": [\n",
    "        \"UCAW-NpUFkMyCNrvRSSGIvDQ\",\n",
    "        \"UC1uvf8YdxSVzthF45kotmJQ\",\n",
    "        \"UCbTVTephX30ZhQF5zwFppBg\",\n",
    "        \"UCS5Oz6CHmeoF7vSad0qqXfw\",\n",
    "        \"UCpGdL9Sn3Q5YWUH2DVUW1Ug\"\n",
    "    ], \"Food\": [\n",
    "        \"UCJQL1Fai-9GlVunsbP4x8Pg\",\n",
    "        \"UCRIZtPl9nb9RiXc9btSTQNw\",\n",
    "        \"UCNbngWUqL2eqRw12yAwcICg\",\n",
    "        \"UC6S5a3MQtr_PSWZxysXkOCg\",\n",
    "        \"UCffs63OaN2nh-6StR6hzfiQ\"\n",
    "    ], \"Gaming\": [\n",
    "        \"UCAW-NpUFkMyCNrvRSSGIvDQ\",\n",
    "        \"UC1uvf8YdxSVzthF45kotmJQ\",\n",
    "        \"UCbTVTephX30ZhQF5zwFppBg\",\n",
    "        \"UCS5Oz6CHmeoF7vSad0qqXfw\",\n",
    "        \"UCpGdL9Sn3Q5YWUH2DVUW1Ug\"\n",
    "    ], \"Fashion\": [\n",
    "        \"UC5zSySQab9SA6Wz569WDgqw\",\n",
    "        \"UCgWfS_47YPVbKx5EK4FLm4A\",\n",
    "        \"UCo5zIpjl2OQkYatd8R0bDaw\",\n",
    "        \"UC-BaXc1TU9i0XSguq9mZwdg\",\n",
    "        \"UC48DOiEvCDu3sThBijwkQ1A\"\n",
    "    ], \"Fitness\": [\n",
    "        \"UCXIJ2-RSIGn53HA-x9RDevA\",\n",
    "        \"UCuA6Ht35K326kBTPTXaWj3g\",\n",
    "        \"UCgBc9iNvvjWDInV6fBeTGXQ\",\n",
    "        \"UCuY1W4AwhhgkB6rsJBtltUA\",\n",
    "        \"UCMTXToEZ6VT5k9GOCFNYjWA\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_test_dataset(channel_ids):\n",
    "    test_dataset = { \"Channel ID\": [] }\n",
    "    for topic in channel_ids:\n",
    "        for channel_id in test_channel_ids[topic]:\n",
    "            test_dataset[\"Channel ID\"].append(channel_id)\n",
    "    test_data = pd.DataFrame.from_dict(test_dataset)\n",
    "    init_test = extend_features(test_data)\n",
    "    return extend_video_features(init_test)\n",
    "            \n",
    "test_data = create_test_dataset(test_channel_ids)\n",
    "test_norm = normalize_data(test_data)\n",
    "test_kernel = kernel_PCA(test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss\n",
    "\n",
    "Since these channels are very similar and commonly recognized as popular channels on YouTube, we will asumme that they should be classified into similar clusters under our model. Thus, we can use the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def entropy(cluster_labels):\n",
    "    freqs = Counter()\n",
    "    for label in cluster_labels:\n",
    "        freqs[label] += 1\n",
    "        \n",
    "    n = len(cluster_labels)\n",
    "    entropy = 0\n",
    "    for label in freqs:\n",
    "        label_prob = freqs[label]/n\n",
    "        entropy += label_prob*np.log(label_prob)\n",
    "    return -entropy\n",
    "    \n",
    "    \n",
    "def total_entropy(y, labels):\n",
    "    m,k = y.shape\n",
    "    labels = np.array(labels)\n",
    "    total_entropy = 0\n",
    "    for i in range(k):\n",
    "        indices = np.where(y[:,i] == 1)[0]\n",
    "        cross_entropy = entropy(labels[indices])\n",
    "        total_entropy += cross_entropy\n",
    "    return total_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a model testing function that returns the total entropy for a given model and another wrapper function that minimize cross entropy loss across models trained on different hyperparameter $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(KM, test_data):\n",
    "    return error\n",
    "\n",
    "def optimize(train, test):\n",
    "    min_error = None\n",
    "    opt_k = None\n",
    "    for k in range(3,7): # 3,4,5,6\n",
    "        kmeans = KMeans(train, k)\n",
    "        test(kmeans, test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pdsfinal/0 or inside your plot.ly account where it is named 'cluster-3d-scatter'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pdsfinal/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "plot_pca = PCA(n)\n",
    "transformed = plot_pca.fit_transform(kernel_data)\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username=\"pdsfinal\", api_key=\"uWfUSo3kfMnXM6gTxmUO\")\n",
    "\n",
    "plot_data = []\n",
    "\n",
    "for i in range(k):\n",
    "    trace = go.Scatter3d(\n",
    "        x=transformed[np.where(labels[:,i] == 1)[0]][:,0],\n",
    "        y=transformed[np.where(labels[:,i] == 1)[0]][:,1],\n",
    "        z=transformed[np.where(labels[:,i] == 1)[0]][:,2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            line=dict(\n",
    "                color='rgba(217,217,217,0.14)',\n",
    "                width=0.5\n",
    "            ),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )\n",
    "    plot_data.append(trace)\n",
    "    \n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=plot_data, layout=layout)\n",
    "py.iplot(fig, filename='cluster-3d-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis\n",
    "\n",
    "\n",
    "\n",
    "### Further Investigation\n",
    "\n",
    "1. Other unsupervised clustering algorithms\n",
    "2. Analyzing genres separately\n",
    "3. Querying Consistently for Time Series Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
