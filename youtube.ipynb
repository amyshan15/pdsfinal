{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing YouTube Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Created by three former PayPal employees in 2005 and later acquired in 2006 by Google, YouTube has tranformed from a simple video hosting service into the world's largest entertainment platform. A community for creators everywhere, YouTube has proven able to support its creators financially as well through Google's targeted advertising program AdSense, and people are using that to quit their jobs and focus on their YouTube channels as a full-time career. In fact, in an age where anyone can pick up their phones and start a vlog, the question of what makes a YouTube channel successful is hotly debated. Today, we'll be looking to characterize different types of channels (popular, growing, declining) across several genres (lifestyle, food & travel, gaming, beauty & fashion) to get an idea of what being a successful YouTuber looks like.\n",
    "\n",
    "#### Q: What does a successful YouTube channel look like?\n",
    "\n",
    "To break this down even further, we're going to answer this question by carrying out the following steps:\n",
    "\n",
    "1. Dataset Assembly\n",
    "2. Feature Extraction\n",
    "3. Model Training\n",
    "3. Cluster Visualization\n",
    "4. Analysis\n",
    "\n",
    "Without further ado, let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Assembly\n",
    "\n",
    "To assemble our dataset, we're going to query the YouTube Data API's search function for our genres (lifestyle, food & travel, gaming, beauty & fashion) and filter the data returned for our 3 types of channels. But in order to do that, we're have to first define what characterizes these types so we know how to filter the data for them.\n",
    "\n",
    "### Channel Types\n",
    "\n",
    "#### Popular\n",
    "\n",
    "A **popular** channel has popular videos (view count), a large following (subscriber count), and active community (comment section). In addition, consistency is also extremely important because it measures the ability of the channel to engage its followers so channels that post a few viral videos are not popular by our definition. Popular channels may not necessarily have the highest view count per video, but accumulate views through consistent content release and the community around them.\n",
    "\n",
    "#### Growing\n",
    "\n",
    "A **growing** channel is like a popular channel except it only started gaining traction recently so its community activity may not be as consistent. Many channels with growing view counts and subscriber counts exist on YouTube, but the key distinction for the growing channels we've defined is the consistency of its content release schedule. Like we mentioned earlier, channels only become popular if they engage their audience consistently and publish content on a regular basis so we'll be filtering for that when we identify growing channels.\n",
    "\n",
    "#### Declining\n",
    "\n",
    "A **declining** channel may have a large subscriber count, but its view count is falling steadily and its comment sections may be less active than they were before. In general, channels decline when they don't stick to content release schedules and fail to engage their audiences, but we're interested in knowing why certain channels that do publish content regularly still fail. That's why we'll focus on again on channels that publish content consistently to see what other features come into play here.\n",
    "\n",
    "Great! Now that we've defined the 3 types of channels we're looking for, assembling the dataset will be a much smoother process. However, it is also important to consider additional filters in order to guarantee that we answer our question above in the most meaningful way possible.\n",
    "\n",
    "### Sampling Bias\n",
    "\n",
    "To understand the motivation behind asking our question, consider music as a genre on YouTube. Vevo is a music video hosting service that partners with huge records labels like the Warner Music Group, and as a part of their contracts, Vevo helps artists like Eminem and Rihanna manage their YouTube channels. As we've defined above, channels like EminemVEVO and RihannaVEVO would be considered **popular** channels, but their success is largely derived from the artists' success in the music industry and other platforms like Spotify. \n",
    "\n",
    "Because of this, we're not extremely interested in investigating what makes these YouTube channels successful because we suspect that a big part of their success is independent of the YouTube channels themselves. That's why we're not considering music as a genre when we're assembling this dataset and why we're not looking into other genres like late night talk shows because most of them present the same confounding variables that influence the success of their channels.\n",
    "\n",
    "### YouTube Data API\n",
    "\n",
    "For querying the YouTube database, we'll be using the YouTube Data API. Here is a link to its official documentation: https://developers.google.com/youtube/v3/.\n",
    "\n",
    "More specifically, we're interested in using a method called **search: list**, which will allow us to query the database with parameters like keywords, location, etc. More information about this method can be found here: https://developers.google.com/youtube/v3/docs/search/list.\n",
    "\n",
    "We start by instantiating an object that establishes an authenticated connection to the YouTube Data Api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from httplib2 import Http\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "API_KEY = \"AIzaSyDI8cZyqHiXp1uh9zr5qPRKe4-bhhaPYUw\" # use your Google Developers Console API key\n",
    "\n",
    "def get_authenticated_service():\n",
    "    return build(API_SERVICE_NAME, API_VERSION, http=Http(), developerKey=API_KEY)\n",
    "\n",
    "client = get_authenticated_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this object to make requests to the YouTube Data API. Below, for example, we have a code snippet that gets 25 channels about ukuleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ukulele Teacher\n",
      "UC1HlihY-iNtOemAlYQq3GXQ\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"part\": \"snippet\",\n",
    "    \"maxResults\": \"25\",\n",
    "    \"q\": \"ukulele\",\n",
    "    \"type\": \"channel\"\n",
    "}\n",
    "\n",
    "response = client.search().list(**params).execute()\n",
    "print(response['items'][0]['snippet']['title'])\n",
    "print(response['items'][0]['id']['channelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the demo code above to query for up to 50 (limit) channels related to each of our topics and add them to a pandas dataframe where we store our dataset. To ensure we obtain as much data for preprocessing as possible, we're considering 3 orderings: relevance, video count, and view count. This will give us something closer to 700 channels rather than 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>UCtE1l7hJ1helcsyxoquNDvQ</td>\n",
       "      <td>NBO FITNESS</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>UCrF6sYzdIgo64yi5GlcSsDw</td>\n",
       "      <td>Pain &amp; Gain Fitness</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>Management: Christian Torres Video Edit: Denis...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                 Channel Name     Created  \\\n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg               Batman Fitness  2016-11-06   \n",
       "690  UCtE1l7hJ1helcsyxoquNDvQ                  NBO FITNESS  2012-06-29   \n",
       "691  UCrF6sYzdIgo64yi5GlcSsDw          Pain & Gain Fitness  2011-03-28   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A  Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                 ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness  \n",
       "690  YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...  Fitness  \n",
       "691  Management: Christian Torres Video Edit: Denis...  Fitness  \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness  \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataset(topics, n=50):\n",
    "    dataset = {\n",
    "        'Channel ID': [],\n",
    "        'Channel Name': [],\n",
    "        'Description': [],\n",
    "        'Created': [],\n",
    "        'Genre': []\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"maxResults\": n,\n",
    "        \"relevanceLanguage\": \"en\",\n",
    "        \"type\": \"channel\"\n",
    "    }\n",
    "\n",
    "    channels = set()\n",
    "    orders = ['relevance', 'viewCount', 'videoCount']\n",
    "    \n",
    "    for topic in topics:\n",
    "        params['q'] = topic\n",
    "        for order in orders:\n",
    "            params['order'] = order\n",
    "            response = client.search().list(**params).execute()\n",
    "\n",
    "            for channel in response['items']:\n",
    "                channel_id = channel['id']['channelId']\n",
    "                channel_name = channel['snippet']['title']\n",
    "                channel_description = channel['snippet']['description']\n",
    "                channel_created = channel['snippet']['publishedAt']\n",
    "                channel_created = channel_created[:channel_created.find('T')]\n",
    "\n",
    "                if channel_id not in channels:\n",
    "                    dataset['Channel ID'].append(channel_id)\n",
    "                    dataset['Channel Name'].append(channel_name)\n",
    "                    dataset['Description'].append(channel_description)\n",
    "                    dataset['Created'].append(channel_created)\n",
    "                    dataset['Genre'].append(topic)\n",
    "                    \n",
    "                    channels.add(channel_id)\n",
    "\n",
    "    return pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "topics = ['Vlog', 'Food', 'Gaming', 'Beauty', 'Fashion', 'Fitness']\n",
    "init_dataset = create_dataset(topics)\n",
    "init_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "Awesome! We have now assembled a dataset around channels in the topics that we care about, but the dataset is lacking in features. Ideally, we would have additional information about the channel so we can characterize them into the 3 types we defined earlier.\n",
    "\n",
    "Below, we will extend our dataset to include the following features about each channel:\n",
    "- view count\n",
    "- subscriber count\n",
    "- video count\n",
    "\n",
    "We'll take these simple channel statistics and engineering some features like Views/Subscriber, which will give us an idea of how much each subscriber to the channel is contributing to the views on that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>UCFoe1jpBJZB9sPUDoLMykGA</td>\n",
       "      <td>Lumowell - fitness | Español</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Wellness y fitness evolucionado. Videos para m...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>440108</td>\n",
       "      <td>595.545332</td>\n",
       "      <td>739</td>\n",
       "      <td>39335272</td>\n",
       "      <td>89.376408</td>\n",
       "      <td>53227.702300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>170</td>\n",
       "      <td>0.242511</td>\n",
       "      <td>701</td>\n",
       "      <td>104568</td>\n",
       "      <td>615.105882</td>\n",
       "      <td>149.169757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>891</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>704</td>\n",
       "      <td>216151</td>\n",
       "      <td>242.593715</td>\n",
       "      <td>307.032670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>95118</td>\n",
       "      <td>162.040886</td>\n",
       "      <td>587</td>\n",
       "      <td>18476925</td>\n",
       "      <td>194.252665</td>\n",
       "      <td>31476.873935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>56812</td>\n",
       "      <td>99.321678</td>\n",
       "      <td>572</td>\n",
       "      <td>12849332</td>\n",
       "      <td>226.172851</td>\n",
       "      <td>22463.867133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name     Created  \\\n",
       "687  UCFoe1jpBJZB9sPUDoLMykGA  Lumowell - fitness | Español  2014-12-23   \n",
       "688  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  2010-10-18   \n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg                Batman Fitness  2016-11-06   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A   Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                  ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "687  Wellness y fitness evolucionado. Videos para m...  Fitness   \n",
       "688  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness   \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness   \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "687            440108        595.545332          739    39335272   \n",
       "688               170          0.242511          701      104568   \n",
       "689               891          1.265625          704      216151   \n",
       "692             95118        162.040886          587    18476925   \n",
       "693             56812         99.321678          572    12849332   \n",
       "\n",
       "     Views/Subscriber   Views/Video  \n",
       "687         89.376408  53227.702300  \n",
       "688        615.105882    149.169757  \n",
       "689        242.593715    307.032670  \n",
       "692        194.252665  31476.873935  \n",
       "693        226.172851  22463.867133  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_channel_stats(channel, params):\n",
    "    params['id'] = channel\n",
    "    res = client.channels().list(**params).execute()\n",
    "    return res['items'][0]['statistics']\n",
    "\n",
    "def extend_features(dataset):\n",
    "    params = {'part': 'statistics'}\n",
    "    extended = {\n",
    "        'Channel ID': [],\n",
    "        'View Count': [],\n",
    "        'Subscriber Count': [],\n",
    "        'Video Count': [],\n",
    "        'Views/Subscriber': [],\n",
    "        'Views/Video': [],\n",
    "        'Subscriber/Video': []\n",
    "    }\n",
    "        \n",
    "    for channel_id in dataset['Channel ID']:\n",
    "        channel_stats = get_channel_stats(channel_id, params)\n",
    "                \n",
    "        viewCount = int(channel_stats['viewCount'])\n",
    "        subscriberCount = int(channel_stats['subscriberCount'])\n",
    "        videoCount = int(channel_stats['videoCount'])\n",
    "        \n",
    "        if videoCount == 0 or viewCount == 0 or subscriberCount == 0:\n",
    "            continue\n",
    "        \n",
    "        extended['Channel ID'].append(channel_id)\n",
    "        extended['View Count'].append(viewCount)\n",
    "        extended['Subscriber Count'].append(subscriberCount)\n",
    "        extended['Video Count'].append(videoCount)\n",
    "        extended['Views/Subscriber'].append(viewCount/subscriberCount)\n",
    "        extended['Views/Video'].append(viewCount/videoCount)\n",
    "        extended['Subscriber/Video'].append(subscriberCount/videoCount)\n",
    "    \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended).set_index('Channel ID')\n",
    "    return dataset.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "    \n",
    "channel_features_dataset = extend_features(init_dataset)\n",
    "channel_features_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Features\n",
    "\n",
    "#### 1. Community Activity\n",
    "\n",
    "Earlier, we identified a channel's community as an important metric in measuring its popularity, and a channel's comment section best reflects this. However, the YouTube API does not return an accurate comment count per channel, so we will query each channels last 20 videos to get an idea of how active the channel's comment sections for each of those videos are.\n",
    "\n",
    "#### 2. Content Consistency\n",
    "\n",
    "Additionally, our sampling targets consistent uploaders because we assume that the uploader is active so we will use these videos to look for how far apart the dates between uploads are on average. If this average is greater than a week, we can conclude that the channel is not a consistent uploader.\n",
    "\n",
    "#### 3. Growth Rate\n",
    "\n",
    "To also characterize whether a channel is growing or declining, we will use the channel's percentage change in view counts across these videos. For example, a percent change of over 20% and under -20% might be labeled as growing and declining respectively, and anything between that will be labeled as a possibly popular channel.\n",
    "\n",
    "#### 4. Favorability\n",
    "\n",
    "Lastly, each video has a statistics on the number of likes and dislikes, which is the only venue through which users can give direct binary feedback on the content uploaders post. Other methods for classifying how people feel rely on analyzing the sentiment of the comments section via NLP methods, and due to high variability we will not be covering that in this notebook. Thus, the higher the ratio of likes to dislikes, the more favorable these videos are as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_to_day = lambda x: np.round(x/86400, 1)\n",
    "\n",
    "def get_video_stats(video, params):\n",
    "    try:\n",
    "        params['id'] = video\n",
    "        res = client.videos().list(**params).execute()\n",
    "        stats = res['items'][0]['statistics']\n",
    "        stats['publishedAt'] = res['items'][0]['snippet']['publishedAt']\n",
    "        return (True, stats)\n",
    "    except:\n",
    "        return (False, None)\n",
    "    \n",
    "def get_channel_videos(channel, n=50):\n",
    "    channel_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'id' : channel\n",
    "    }\n",
    "    res = client.channels().list(**channel_params).execute()\n",
    "    upload_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    playlist_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'playlistId' : upload_id,\n",
    "        'maxResults' : n\n",
    "    }\n",
    "    uploads = client.playlistItems().list(**playlist_params).execute()\n",
    "    return uploads['items']\n",
    "\n",
    "def calc_channel_video_stats(dates, views, likes, dislikes, comments):\n",
    "    video_stats = dict()\n",
    "    \n",
    "    views, likes, dislikes, comments = np.array(views), np.array(likes), np.array(dislikes), np.array(comments)\n",
    "    dates = list(map(lambda x: dateutil.parser.parse(x), dates))\n",
    "        \n",
    "    # average views per upload\n",
    "    video_stats['Views/Upload'] = np.mean(views)\n",
    "    # average likes per upload\n",
    "    video_stats['Likes/Upload'] = np.mean(likes)\n",
    "    # average dislikes per upload\n",
    "    video_stats['Dislikes/Upload'] = np.mean(dislikes)\n",
    "    # average comments per upload\n",
    "    video_stats['Comments/Upload'] = np.mean(comments)\n",
    "    # like to views ratio\n",
    "    video_stats['Likes/View'] = np.mean(likes/views)*100\n",
    "    # dislikes to views ratio\n",
    "    video_stats['Dislikes/View'] = np.mean(dislikes/views)*100\n",
    "    # comments to views ratio\n",
    "    video_stats['Comments/View'] = np.mean(comments/views)*100\n",
    "    # upload frequency\n",
    "    time_diff = (dates[-1] - dates[0]).total_seconds()\n",
    "    video_stats['Days/Upload'] = sec_to_day(time_diff / len(dates))\n",
    "\n",
    "    upload_days = list(map(lambda x: sec_to_day((x - dates[0]).total_seconds()), dates))\n",
    "    m, b, r, p, err = stats.linregress(upload_days, views)\n",
    "    # growth rate (views)\n",
    "    video_stats['Growth Rate'] = (m / views[0]) * 100\n",
    "    \n",
    "    return video_stats\n",
    "    \n",
    "def get_channel_video_stats(channel):\n",
    "    published_dates = []\n",
    "    view_counts = []\n",
    "    like_counts = []\n",
    "    dislike_counts = []\n",
    "    comment_counts = []\n",
    "    \n",
    "    video_params = { 'part': 'snippet,statistics' }\n",
    "    \n",
    "    channel_videos = get_channel_videos(channel)\n",
    "    \n",
    "    if len(channel_videos) == 0:\n",
    "        return None\n",
    "        \n",
    "    for i in range(len(channel_videos)-1, -1, -1):\n",
    "        video_info = channel_videos[i]\n",
    "        video_id = video_info['contentDetails']['videoId']\n",
    "        \n",
    "        success, video_stats = get_video_stats(video_id, video_params)\n",
    "\n",
    "        # publishedAt, viewCount, likeCount, dislikeCount, commentCount\n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        published_dates.append(video_stats['publishedAt'])\n",
    "        \n",
    "        view_counts.append(int(video_stats['viewCount']) if 'viewCount' in video_stats else 0)\n",
    "        like_counts.append(int(video_stats['likeCount']) if 'likeCount' in video_stats else 0)\n",
    "        dislike_counts.append(int(video_stats['dislikeCount']) if 'dislikeCount' in video_stats else 0)\n",
    "        comment_counts.append(int(video_stats['commentCount']) if 'commentCount' in video_stats else 0)\n",
    "                        \n",
    "    return calc_channel_video_stats(published_dates, view_counts, like_counts, dislike_counts, comment_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:106: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = r_num / ssxm\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:116: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    }
   ],
   "source": [
    "# Channels with no videos returned are filtered out (ex: UCOpNcN46UbXVtpKMrmU4Abg)\n",
    "\n",
    "def extend_video_features(data):\n",
    "    extended_video = { 'Channel ID': [] }\n",
    "        \n",
    "    for channel_id in data['Channel ID']:            \n",
    "        channel_video_stats = get_channel_video_stats(channel_id)\n",
    "        \n",
    "        if channel_video_stats == None:\n",
    "            continue\n",
    "                    \n",
    "        extended_video['Channel ID'].append(channel_id)\n",
    "        for video_stat in channel_video_stats:\n",
    "            if video_stat not in extended_video:\n",
    "                extended_video[video_stat] = []\n",
    "            extended_video[video_stat].append(channel_video_stats[video_stat])\n",
    "                                        \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended_video).set_index('Channel ID')\n",
    "    return data.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "\n",
    "dataset = extend_video_features(channel_features_dataset)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "\n",
    "We now have 15 features on 700 channels on its most recent 25 videos that we'll store in a csv file \"youtube-data.csv\", and we're ready to extract the important features and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('youtube-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1318, 21)\n"
     ]
    }
   ],
   "source": [
    "# get more data\n",
    "def create_dataset(topics, n=50): # should refactor this function to take in orders\n",
    "    dataset = {\n",
    "        'Channel ID': [],\n",
    "        'Channel Name': [],\n",
    "        'Description': [],\n",
    "        'Created': [],\n",
    "        'Genre': []\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"maxResults\": n,\n",
    "        \"relevanceLanguage\": \"en\",\n",
    "        \"type\": \"channel\"\n",
    "    }\n",
    "\n",
    "    channels = set()\n",
    "    orders = ['date', 'rating', 'title']\n",
    "    \n",
    "    for topic in topics:\n",
    "        params['q'] = topic\n",
    "        for order in orders:\n",
    "            params['order'] = order\n",
    "            response = client.search().list(**params).execute()\n",
    "\n",
    "            for channel in response['items']:\n",
    "                channel_id = channel['id']['channelId']\n",
    "                channel_name = channel['snippet']['title']\n",
    "                channel_description = channel['snippet']['description']\n",
    "                channel_created = channel['snippet']['publishedAt']\n",
    "                channel_created = channel_created[:channel_created.find('T')]\n",
    "\n",
    "                if channel_id not in channels:\n",
    "                    dataset['Channel ID'].append(channel_id)\n",
    "                    dataset['Channel Name'].append(channel_name)\n",
    "                    dataset['Description'].append(channel_description)\n",
    "                    dataset['Created'].append(channel_created)\n",
    "                    dataset['Genre'].append(topic)\n",
    "                    \n",
    "                    channels.add(channel_id)\n",
    "\n",
    "    return pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "# topics = ['Vlog', 'Food', 'Gaming', 'Beauty', 'Fashion', 'Fitness']\n",
    "# more_data = create_dataset(topics)\n",
    "# more_data = extend_features(more_data)\n",
    "# more_data = extend_video_features(more_data)\n",
    "# more_data = more_data.set_index('Channel ID')\n",
    "# data_set = prev_data.append(more_data)\n",
    "\n",
    "# more_data.to_csv('more_data.csv')\n",
    "\n",
    "# data_set.to_csv('all_data.csv')\n",
    "\n",
    "print(data_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making the data pretty for k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1318, 22)\n",
      "(609, 22)\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('all_data.csv')\n",
    "d = d.replace([np.inf, -np.inf], np.nan)\n",
    "print(d.shape)\n",
    "\n",
    "d = d.dropna()\n",
    "print(d.shape)\n",
    "\n",
    "a = d[['Subscriber Count', 'Views/Video', 'Days/Upload', 'Growth Rate', 'Comments/Upload']]\n",
    "b = d[['Subscriber Count', 'View Count', 'Days/Upload', 'Growth Rate', 'Comments/Upload']]\n",
    "c = d[['Subscriber/Video', 'Views/Video', 'Days/Upload', 'Growth Rate', 'Comments/Upload']]\n",
    "\n",
    "# data_set = data_set.drop(['Channel ID', 'Channel Name', 'Created', 'Description', 'Genre'], axis=1)\n",
    "a_d = a.as_matrix()\n",
    "b_d = b.as_matrix()\n",
    "c_d = c.as_matrix()\n",
    "# reduced_data = d.as_matrix()\n",
    "# print(reduced_data.shape)\n",
    "\n",
    "# pca = PCA(6)\n",
    "# reduced_data = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k means stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dzq homework 5\n",
    "import math\n",
    "\n",
    "def distance_matrix(X):\n",
    "    m,n = X.shape\n",
    "    M = np.zeros((m,m))\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            M[i,j] = np.sum((X[i]-X[j])**2)\n",
    "    return M\n",
    "\n",
    "class KMeans:\n",
    "    def init_centers(self, X, k):\n",
    "        \"\"\" Initialize the starting k centers, using the KMeans++ algorithm. \n",
    "            Args: \n",
    "                X (numpy 2D matrix) : data matrix, each row is an example\n",
    "                k (float) : number of clusters\n",
    "            Return: \n",
    "                (numpy 2D matrix) : matrix of centers, each row is a center\n",
    "        \"\"\"\n",
    "        centers = []\n",
    "        m = X.shape[0]\n",
    "        M = distance_matrix(X)\n",
    "        pos = np.arange(len(X))\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                center = X[np.random.choice(pos)]\n",
    "            else:\n",
    "                # Calculate probabilities\n",
    "                probs = []\n",
    "                for x in range(m):\n",
    "                    # Calculate each vector's probability\n",
    "                    sub_probs = []\n",
    "                    for y in range(m):\n",
    "                        sub_prob = []\n",
    "                        for center in centers:\n",
    "                            dist_to_center = np.sum((X[y]-center)**2)\n",
    "                            sub_prob.append(dist_to_center)\n",
    "                        val = np.min(sub_prob)\n",
    "                        sub_probs.append(val)\n",
    "                    \n",
    "                    num = sub_probs[x]\n",
    "                    denom = np.sum(sub_probs)\n",
    "                    \n",
    "                    prob = num/denom\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "                center = X[np.random.choice(pos, p=probs)]\n",
    "                \n",
    "            centers.append(center)\n",
    "            \n",
    "        centers = np.array(centers)\n",
    "        return centers\n",
    "        \n",
    "    def assign_clusters(self, X, centers):\n",
    "        \"\"\" Given the data and the centers, assign clusters to all the examples. \n",
    "            Args: \n",
    "                X (numpy 2D matrix) : data matrix, each row is an example\n",
    "                centers (numpy 2D matrix) : matrix of centers, each row is a center\n",
    "            Return: \n",
    "                (numpy 2D matrix) : 1 hot encoding of cluster assignments for each example\n",
    "        \"\"\"\n",
    "        m,k = X.shape[0], len(centers) \n",
    "        clusters = np.zeros((m,k))\n",
    "        for i in range(m):\n",
    "            probs = []\n",
    "            for j in range(k):\n",
    "                dist = np.sum((X[i]-centers[j])**2)\n",
    "                probs.append(dist)\n",
    "            y = np.argmin(probs)\n",
    "            clusters[i,y] = 1\n",
    "        return clusters\n",
    "    \n",
    "    def compute_means(self, X, y):\n",
    "        \"\"\" Given the data and the cluster labels, compute the new cluster centers. \n",
    "            Args: \n",
    "                X (numpy 2D matrix) : data matrix, each row is an example\n",
    "                y (numpy 2D matrix) : 1 hot encoding of cluster assignments for each example\n",
    "            Return: \n",
    "                (numpy 2D matrix) : matrix of centers, each row is a center\n",
    "        \"\"\"\n",
    "        m, n, k = X.shape[0], X.shape[1], y.shape[1]\n",
    "        centers = np.zeros((k,n))\n",
    "        \n",
    "        for j in range(k):\n",
    "            cluster = np.zeros(n)\n",
    "            num_cluster = 0\n",
    "            for i in range(m):\n",
    "                if y[i,j] == 1:\n",
    "                    num_cluster += 1\n",
    "                    cluster = cluster + X[i]\n",
    "            center = cluster / num_cluster\n",
    "            centers[j,:] = center\n",
    "            \n",
    "        return centers    \n",
    "    def train(self, X, centers, niters=20):\n",
    "        \"\"\" Args: \n",
    "                X (numpy 2D matrix) : data matrix, each row is an example\n",
    "                centers (numpy 2D matrix) : initial matrix of centers, each row is a center\n",
    "            Return: \n",
    "                (y, centers) : tuple of 1 hot encoding of cluster assignments for each example \n",
    "                               the resulting cluster centers\n",
    "        \"\"\"\n",
    "        for i in range(niters):\n",
    "            clusters = self.assign_clusters(X, centers)\n",
    "            centers = self.compute_means(X, clusters)\n",
    "                    \n",
    "        return (clusters, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(reduced_data.shape)\n",
    "k = 5\n",
    "KM = KMeans()\n",
    "mu = KM.init_centers(a_d, k)\n",
    "(y_a, centers) = KM.train(a_d, mu)\n",
    "\n",
    "\n",
    "KM = KMeans()\n",
    "mu = KM.init_centers(b_d, k)\n",
    "(y_b, centers) = KM.train(b_d, mu)\n",
    "\n",
    "KM = KMeans()\n",
    "mu = KM.init_centers(c_d, k)\n",
    "(y_c, centers) = KM.train(c_d, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "74\n",
      "2\n",
      "19\n",
      "507\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(2) #2-dimensional PCA\n",
    "transformed = pd.DataFrame(pca.fit_transform(a_d))\n",
    "\n",
    "print(type(y))\n",
    "print(type(transformed))\n",
    "\n",
    "transformed = transformed.as_matrix()\n",
    "\n",
    "print(type(transformed))\n",
    "\n",
    "# print(transformed.shape)\n",
    "\n",
    "print(len(np.where(y_a[:,0]==1)[0]))\n",
    "print(len(np.where(y_a[:,1]==1)[0]))\n",
    "print(len(np.where(y_a[:,2]==1)[0]))\n",
    "print(len(np.where(y_a[:,3]==1)[0]))\n",
    "print(len(np.where(y_a[:,4]==1)[0]))\n",
    "print()\n",
    "\n",
    "pca = PCA(2) #2-dimensional PCA\n",
    "transformed = pd.DataFrame(pca.fit_transform(b_d))\n",
    "\n",
    "print(type(y))\n",
    "print(type(transformed))\n",
    "\n",
    "transformed = transformed.as_matrix()\n",
    "\n",
    "print(type(transformed))\n",
    "\n",
    "# print(transformed.shape)\n",
    "\n",
    "print(len(np.where(y_b[:,0]==1)[0]))\n",
    "print(len(np.where(y_b[:,1]==1)[0]))\n",
    "print(len(np.where(y_b[:,2]==1)[0]))\n",
    "print(len(np.where(y_b[:,3]==1)[0]))\n",
    "print(len(np.where(y_b[:,4]==1)[0]))\n",
    "print()\n",
    "\n",
    "pca = PCA(2) #2-dimensional PCA\n",
    "transformed = pd.DataFrame(pca.fit_transform(c_d))\n",
    "\n",
    "print(type(y))\n",
    "print(type(transformed))\n",
    "\n",
    "transformed = transformed.as_matrix()\n",
    "\n",
    "\n",
    "# print(transformed.shape)\n",
    "\n",
    "print(len(np.where(y_c[:,0]==1)[0]))\n",
    "print(len(np.where(y_c[:,1]==1)[0]))\n",
    "print(len(np.where(y_c[:,2]==1)[0]))\n",
    "print(len(np.where(y_c[:,3]==1)[0]))\n",
    "print(len(np.where(y_c[:,4]==1)[0]))\n",
    "print()\n",
    "\n",
    "\n",
    "# plt.scatter(transformed[np.where(y[:,0] == 1)[0]][0], transformed[np.where(y[:,0] == 1)[0]][1], label='Class 1', c='red')\n",
    "# plt.scatter(transformed[np.where(y[:,1] == 1)[0]][0], transformed[np.where(y[:,1] == 1)[0]][1], label='Class 2', c='blue')\n",
    "# plt.scatter(transformed[np.where(y[:,2] == 1)[0]][0], transformed[np.where(y[:,2] == 1)[0]][1], label='Class 3', c='lightgreen')\n",
    "# plt.scatter(transformed[np.where(y[:,3] == 1)[0]][0], transformed[np.where(y[:,3] == 1)[0]][1], label='Class 4', c='yellow')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
