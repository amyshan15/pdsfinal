{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing YouTube Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Created by three former PayPal employees in 2005 and later acquired in 2006 by Google, YouTube has tranformed from a simple video hosting service into the world's largest entertainment platform. A community for creators everywhere, YouTube has proven able to support its creators financially as well through Google's targeted advertising program AdSense, and people are using that to quit their jobs and focus on their YouTube channels as a full-time career. In fact, in an age where anyone can pick up their phones and start a vlog, the question of what makes a YouTube channel successful is hotly debated. Today, we'll be looking at channels across several genres (lifestyle, food & travel, gaming, beauty & fashion) to get an idea of what being a successful YouTuber looks like.\n",
    "\n",
    "#### Q: What does a successful YouTube channel look like?\n",
    "\n",
    "To break this down even further, we're going to answer this question by carrying out the following steps:\n",
    "\n",
    "1. [Dataset Assembly](#1.-Dataset-Assembly)\n",
    "2. [Feature Engineering](#2.-Feature-Engineering)\n",
    "3. [Model Training](#3.-Model-Training)\n",
    "4. [Cluster Visualization](#4.-Cluster-Visualization)\n",
    "5. [Future Directions](#5.-Future-Directions)\n",
    "\n",
    "Without further ado, let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Assembly\n",
    "\n",
    "To assemble our dataset, we're going to query the YouTube Data API's search function for our genres (lifestyle, food & travel, gaming, beauty & fashion). Before we do this, however, it would be helpful to define the 3 major types of channels we expect to find.\n",
    "\n",
    "### Channel Types\n",
    "\n",
    "#### Popular\n",
    "\n",
    "A **popular** channel has popular videos (large view/video count), a large following (large subscriber count), and an active community (buzzing comment section) around it. Popular channels may not necessarily have the highest view count per video, but accumulate views through consistent content release and the community around them.\n",
    "\n",
    "#### Growing\n",
    "\n",
    "A **growing** channel is like a popular channel except it only started gaining traction recently so its community activity may not be as consistent. Many channels with growing view counts and subscriber counts exist on YouTube, but the key distinction for the growing channels we've defined is the consistency of its content release schedules since channels only become popular if they engage their audience consistently.\n",
    "\n",
    "#### Declining\n",
    "\n",
    "A **declining** channel may have a large subscriber count, but its view count is falling steadily and its comment sections may be less active than they were before. In general, channels decline when they don't stick to content release schedules and fail to engage their audiences, but we're also interested in knowing why certain channels that do publish content regularly still fail.\n",
    "\n",
    "Great! Now that we've defined the 3 types of channels we're looking for, assembling the dataset will be a much more guided process. However, it is also important to consider additional filters in order to guarantee that we answer our question above in the most meaningful way possible.\n",
    "\n",
    "### Sampling Bias\n",
    "\n",
    "To understand the motivation behind asking our question, consider music as a genre on YouTube. Vevo is a music video hosting service that partners with huge records labels like the Warner Music Group, and as a part of their contracts, Vevo helps artists like Eminem and Rihanna manage their YouTube channels. As we've defined above, channels like EminemVEVO and RihannaVEVO would be considered **popular** channels, but their success is largely derived from the artists' success in the music industry and other platforms like Spotify. \n",
    "\n",
    "Because of this, we're not extremely interested in investigating what makes these YouTube channels successful because we suspect that a big part of their success is independent of the YouTube channels themselves. That's why we're not considering music as a genre when we're assembling this dataset and why we're not looking into other genres like late night talk shows because most of them present the same confounding variables that influence the success of their channels.\n",
    "\n",
    "### YouTube Data API\n",
    "\n",
    "For querying the YouTube database, we'll be using the YouTube Data API. Here is a link to its official documentation: https://developers.google.com/youtube/v3/.\n",
    "\n",
    "More specifically, we're interested in using a method called **search: list**, which will allow us to query the database with parameters like keywords, location, etc. More information about this method can be found here: https://developers.google.com/youtube/v3/docs/search/list.\n",
    "\n",
    "We start by instantiating an object that establishes an authenticated connection to the YouTube Data Api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from httplib2 import Http\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "API_KEY = \"AIzaSyDI8cZyqHiXp1uh9zr5qPRKe4-bhhaPYUw\" # use your Google Developers Console API key\n",
    "\n",
    "def get_authenticated_service():\n",
    "    return build(API_SERVICE_NAME, API_VERSION, http=Http(), developerKey=API_KEY)\n",
    "\n",
    "client = get_authenticated_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this object to make requests to the YouTube Data API. Below, for example, we have a code snippet that gets 25 channels about ukuleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ukulele Teacher\n",
      "UC1HlihY-iNtOemAlYQq3GXQ\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"part\": \"snippet\",\n",
    "    \"maxResults\": \"25\",\n",
    "    \"q\": \"ukulele\",\n",
    "    \"type\": \"channel\"\n",
    "}\n",
    "\n",
    "response = client.search().list(**params).execute()\n",
    "print(response['items'][0]['snippet']['title'])\n",
    "print(response['items'][0]['id']['channelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the demo code above to query for up to 50 (limit) channels related to each of our topics and add them to a pandas dataframe where we store our dataset. To ensure we obtain as much data for preprocessing as possible, we're considering 3 orderings: relevance, video count, and view count. This will give us something closer to 700 channels rather than 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>UCtE1l7hJ1helcsyxoquNDvQ</td>\n",
       "      <td>NBO FITNESS</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>UCrF6sYzdIgo64yi5GlcSsDw</td>\n",
       "      <td>Pain &amp; Gain Fitness</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>Management: Christian Torres Video Edit: Denis...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                 Channel Name     Created  \\\n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg               Batman Fitness  2016-11-06   \n",
       "690  UCtE1l7hJ1helcsyxoquNDvQ                  NBO FITNESS  2012-06-29   \n",
       "691  UCrF6sYzdIgo64yi5GlcSsDw          Pain & Gain Fitness  2011-03-28   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A  Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                 ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness  \n",
       "690  YOUTUBE FITNESS PERSONALITY, TRAINER, FAMILY M...  Fitness  \n",
       "691  Management: Christian Torres Video Edit: Denis...  Fitness  \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness  \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataset(topics, n=50):\n",
    "    dataset = {\n",
    "        'Channel ID': [],\n",
    "        'Channel Name': [],\n",
    "        'Description': [],\n",
    "        'Created': [],\n",
    "        'Genre': []\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"maxResults\": n,\n",
    "        \"relevanceLanguage\": \"en\",\n",
    "        \"type\": \"channel\"\n",
    "    }\n",
    "\n",
    "    channels = set()\n",
    "    orders = ['relevance', 'viewCount', 'videoCount']\n",
    "    \n",
    "    for topic in topics:\n",
    "        params['q'] = topic\n",
    "        for order in orders:\n",
    "            params['order'] = order\n",
    "            response = client.search().list(**params).execute()\n",
    "\n",
    "            for channel in response['items']:\n",
    "                channel_id = channel['id']['channelId']\n",
    "                channel_name = channel['snippet']['title']\n",
    "                channel_description = channel['snippet']['description']\n",
    "                channel_created = channel['snippet']['publishedAt']\n",
    "                channel_created = channel_created[:channel_created.find('T')]\n",
    "\n",
    "                if channel_id not in channels:\n",
    "                    dataset['Channel ID'].append(channel_id)\n",
    "                    dataset['Channel Name'].append(channel_name)\n",
    "                    dataset['Description'].append(channel_description)\n",
    "                    dataset['Created'].append(channel_created)\n",
    "                    dataset['Genre'].append(topic)\n",
    "                    \n",
    "                    channels.add(channel_id)\n",
    "\n",
    "    return pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "topics = ['Vlog', 'Food', 'Gaming', 'Beauty', 'Fashion', 'Fitness']\n",
    "init_dataset = create_dataset(topics)\n",
    "init_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extension\n",
    "\n",
    "Awesome! We have now assembled a dataset around channels in the topics that we care about, but the dataset is lacking in features. Ideally, we would have additional information about the channel so we can characterize them into the 3 types we defined earlier.\n",
    "\n",
    "Below, we will extend our dataset to include the following features about each channel:\n",
    "- view count\n",
    "- subscriber count\n",
    "- video count\n",
    "\n",
    "We'll take these simple channel statistics and engineering some features like Views/Subscriber, which will give us an idea of how much each subscriber to the channel is contributing to the views on that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>UCFoe1jpBJZB9sPUDoLMykGA</td>\n",
       "      <td>Lumowell - fitness | Español</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Wellness y fitness evolucionado. Videos para m...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>440640</td>\n",
       "      <td>596.265223</td>\n",
       "      <td>739</td>\n",
       "      <td>39395881</td>\n",
       "      <td>89.406048</td>\n",
       "      <td>53309.717185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>170</td>\n",
       "      <td>0.242511</td>\n",
       "      <td>701</td>\n",
       "      <td>104665</td>\n",
       "      <td>615.676471</td>\n",
       "      <td>149.308131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>897</td>\n",
       "      <td>1.270538</td>\n",
       "      <td>706</td>\n",
       "      <td>217912</td>\n",
       "      <td>242.934225</td>\n",
       "      <td>308.657224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>95484</td>\n",
       "      <td>162.387755</td>\n",
       "      <td>588</td>\n",
       "      <td>18526473</td>\n",
       "      <td>194.026989</td>\n",
       "      <td>31507.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>56842</td>\n",
       "      <td>99.374126</td>\n",
       "      <td>572</td>\n",
       "      <td>12854403</td>\n",
       "      <td>226.142694</td>\n",
       "      <td>22472.732517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name     Created  \\\n",
       "687  UCFoe1jpBJZB9sPUDoLMykGA  Lumowell - fitness | Español  2014-12-23   \n",
       "688  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  2010-10-18   \n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg                Batman Fitness  2016-11-06   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A   Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                  ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "687  Wellness y fitness evolucionado. Videos para m...  Fitness   \n",
       "688  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness   \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness   \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "687            440640        596.265223          739    39395881   \n",
       "688               170          0.242511          701      104665   \n",
       "689               897          1.270538          706      217912   \n",
       "692             95484        162.387755          588    18526473   \n",
       "693             56842         99.374126          572    12854403   \n",
       "\n",
       "     Views/Subscriber   Views/Video  \n",
       "687         89.406048  53309.717185  \n",
       "688        615.676471    149.308131  \n",
       "689        242.934225    308.657224  \n",
       "692        194.026989  31507.607143  \n",
       "693        226.142694  22472.732517  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_channel_stats(channel, params):\n",
    "    params['id'] = channel\n",
    "    res = client.channels().list(**params).execute()\n",
    "    return res['items'][0]['statistics']\n",
    "\n",
    "def extend_features(dataset):\n",
    "    params = {'part': 'statistics'}\n",
    "    extended = {\n",
    "        'Channel ID': [],\n",
    "        'View Count': [],\n",
    "        'Subscriber Count': [],\n",
    "        'Video Count': [],\n",
    "        'Views/Subscriber': [],\n",
    "        'Views/Video': [],\n",
    "        'Subscriber/Video': []\n",
    "    }\n",
    "        \n",
    "    for channel_id in dataset['Channel ID']:\n",
    "        channel_stats = get_channel_stats(channel_id, params)\n",
    "                \n",
    "        viewCount = int(channel_stats['viewCount'])\n",
    "        subscriberCount = int(channel_stats['subscriberCount'])\n",
    "        videoCount = int(channel_stats['videoCount'])\n",
    "        \n",
    "        if videoCount == 0 or viewCount == 0 or subscriberCount == 0:\n",
    "            continue\n",
    "        \n",
    "        extended['Channel ID'].append(channel_id)\n",
    "        extended['View Count'].append(viewCount)\n",
    "        extended['Subscriber Count'].append(subscriberCount)\n",
    "        extended['Video Count'].append(videoCount)\n",
    "        extended['Views/Subscriber'].append(viewCount/subscriberCount)\n",
    "        extended['Views/Video'].append(viewCount/videoCount)\n",
    "        extended['Subscriber/Video'].append(subscriberCount/videoCount)\n",
    "    \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended).set_index('Channel ID')\n",
    "    return dataset.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "    \n",
    "channel_features_dataset = extend_features(init_dataset)\n",
    "channel_features_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Features\n",
    "\n",
    "#### 1. Community Activity\n",
    "\n",
    "Earlier, we identified a channel's community as an important metric in measuring its popularity, and a channel's comment section best reflects this. For this we will query each channels last 50 videos and average across the comments for these videos.\n",
    "\n",
    "#### 2. Content Consistency\n",
    "\n",
    "Additionally, our sampling targets consistent uploaders because we assume that the uploader is active so we will use these videos to look for how far apart the dates between uploads are on average.\n",
    "\n",
    "#### 3. Growth Rate\n",
    "\n",
    "To also characterize whether a channel is growing or declining, we will use the channel's percentage change in view counts across these videos by fitting a linear regression line onto these datapoints.\n",
    "\n",
    "#### 4. Favorability\n",
    "\n",
    "Lastly, each video has a statistics on the number of likes and dislikes, which is the only venue through which users can give direct binary feedback on the content uploaders post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sec_to_day = lambda x: np.round(x/86400, 1)\n",
    "\n",
    "def get_video_stats(video, params):\n",
    "    try:\n",
    "        params['id'] = video\n",
    "        res = client.videos().list(**params).execute()\n",
    "        stats = res['items'][0]['statistics']\n",
    "        stats['publishedAt'] = res['items'][0]['snippet']['publishedAt']\n",
    "        return (True, stats)\n",
    "    except:\n",
    "        return (False, None)\n",
    "    \n",
    "def get_channel_videos(channel, n=50):\n",
    "    channel_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'id' : channel\n",
    "    }\n",
    "    res = client.channels().list(**channel_params).execute()\n",
    "    upload_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    playlist_params = {\n",
    "        'part': 'contentDetails',\n",
    "        'playlistId' : upload_id,\n",
    "        'maxResults' : n\n",
    "    }\n",
    "    uploads = client.playlistItems().list(**playlist_params).execute()\n",
    "    return uploads['items']\n",
    "\n",
    "def calc_channel_video_stats(dates, views, likes, dislikes, comments):\n",
    "    video_stats = dict()\n",
    "    \n",
    "    views, likes, dislikes, comments = np.array(views), np.array(likes), np.array(dislikes), np.array(comments)\n",
    "    dates = list(map(lambda x: dateutil.parser.parse(x), dates))\n",
    "        \n",
    "    # average views per upload\n",
    "    video_stats['Views/Upload'] = np.mean(views)\n",
    "    # average likes per upload\n",
    "    video_stats['Likes/Upload'] = np.mean(likes)\n",
    "    # average dislikes per upload\n",
    "    video_stats['Dislikes/Upload'] = np.mean(dislikes)\n",
    "    # average comments per upload\n",
    "    video_stats['Comments/Upload'] = np.mean(comments)\n",
    "    # like to views ratio\n",
    "    video_stats['Likes/View'] = np.mean(likes/views)*100\n",
    "    # dislikes to views ratio\n",
    "    video_stats['Dislikes/View'] = np.mean(dislikes/views)*100\n",
    "    # comments to views ratio\n",
    "    video_stats['Comments/View'] = np.mean(comments/views)*100\n",
    "    # upload frequency\n",
    "    time_diff = (dates[-1] - dates[0]).total_seconds()\n",
    "    video_stats['Days/Upload'] = sec_to_day(time_diff / len(dates))\n",
    "\n",
    "    upload_days = list(map(lambda x: sec_to_day((x - dates[0]).total_seconds()), dates))\n",
    "    m, b, r, p, err = stats.linregress(upload_days, views)\n",
    "    # growth rate (views)\n",
    "    video_stats['Growth Rate'] = (m / views[0]) * 100\n",
    "    \n",
    "    return video_stats\n",
    "    \n",
    "def get_channel_video_stats(channel):\n",
    "    published_dates = []\n",
    "    view_counts = []\n",
    "    like_counts = []\n",
    "    dislike_counts = []\n",
    "    comment_counts = []\n",
    "    \n",
    "    video_params = { 'part': 'snippet,statistics' }\n",
    "    \n",
    "    channel_videos = get_channel_videos(channel)\n",
    "    \n",
    "    if len(channel_videos) == 0:\n",
    "        return None\n",
    "        \n",
    "    for i in range(len(channel_videos)-1, -1, -1):\n",
    "        video_info = channel_videos[i]\n",
    "        video_id = video_info['contentDetails']['videoId']\n",
    "        \n",
    "        success, video_stats = get_video_stats(video_id, video_params)\n",
    "\n",
    "        # publishedAt, viewCount, likeCount, dislikeCount, commentCount\n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        published_dates.append(video_stats['publishedAt'])\n",
    "        \n",
    "        view_counts.append(int(video_stats['viewCount']) if 'viewCount' in video_stats else 0)\n",
    "        like_counts.append(int(video_stats['likeCount']) if 'likeCount' in video_stats else 0)\n",
    "        dislike_counts.append(int(video_stats['dislikeCount']) if 'dislikeCount' in video_stats else 0)\n",
    "        comment_counts.append(int(video_stats['commentCount']) if 'commentCount' in video_stats else 0)\n",
    "                        \n",
    "    return calc_channel_video_stats(published_dates, view_counts, like_counts, dislike_counts, comment_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:106: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = r_num / ssxm\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:116: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py:118: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sterrest = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "      <th>Comments/Upload</th>\n",
       "      <th>Comments/View</th>\n",
       "      <th>Days/Upload</th>\n",
       "      <th>Dislikes/Upload</th>\n",
       "      <th>Dislikes/View</th>\n",
       "      <th>Growth Rate</th>\n",
       "      <th>Likes/Upload</th>\n",
       "      <th>Likes/View</th>\n",
       "      <th>Views/Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>UCFoe1jpBJZB9sPUDoLMykGA</td>\n",
       "      <td>Lumowell - fitness | Español</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Wellness y fitness evolucionado. Videos para m...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>440108</td>\n",
       "      <td>595.545332</td>\n",
       "      <td>739</td>\n",
       "      <td>39335272</td>\n",
       "      <td>89.376408</td>\n",
       "      <td>53227.702300</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.093251</td>\n",
       "      <td>-1.067616</td>\n",
       "      <td>465.14</td>\n",
       "      <td>7.216093</td>\n",
       "      <td>6642.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>170</td>\n",
       "      <td>0.242511</td>\n",
       "      <td>701</td>\n",
       "      <td>104568</td>\n",
       "      <td>615.105882</td>\n",
       "      <td>149.169757</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.273421</td>\n",
       "      <td>47.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UCXFazK2sRYkuNgZ_Xs7BKUg</td>\n",
       "      <td>Batman Fitness</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Salut à tous je suis Batman fitness de la vérité.</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>891</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>704</td>\n",
       "      <td>216151</td>\n",
       "      <td>242.593715</td>\n",
       "      <td>307.032670</td>\n",
       "      <td>14.58</td>\n",
       "      <td>6.234693</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.06</td>\n",
       "      <td>2.180904</td>\n",
       "      <td>-6.571514</td>\n",
       "      <td>15.96</td>\n",
       "      <td>7.857068</td>\n",
       "      <td>253.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>UCYi4JJcjDYtNGLX0N6e7g5A</td>\n",
       "      <td>Men's Health &amp; Fitness Tips</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Men Health &amp; Fitness and Sexual Tips , This Ch...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>95118</td>\n",
       "      <td>162.040886</td>\n",
       "      <td>587</td>\n",
       "      <td>18476925</td>\n",
       "      <td>194.252665</td>\n",
       "      <td>31476.873935</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15.44</td>\n",
       "      <td>0.175641</td>\n",
       "      <td>-591.460505</td>\n",
       "      <td>290.94</td>\n",
       "      <td>2.322659</td>\n",
       "      <td>20110.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>UCLDw7ummSJnILbMZn2Azf2g</td>\n",
       "      <td>ON THE RADAR</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>56812</td>\n",
       "      <td>99.321678</td>\n",
       "      <td>572</td>\n",
       "      <td>12849332</td>\n",
       "      <td>226.172851</td>\n",
       "      <td>22463.867133</td>\n",
       "      <td>28.80</td>\n",
       "      <td>1.893966</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>-1.409487</td>\n",
       "      <td>151.20</td>\n",
       "      <td>6.117708</td>\n",
       "      <td>5736.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name     Created  \\\n",
       "687  UCFoe1jpBJZB9sPUDoLMykGA  Lumowell - fitness | Español  2014-12-23   \n",
       "688  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  2010-10-18   \n",
       "689  UCXFazK2sRYkuNgZ_Xs7BKUg                Batman Fitness  2016-11-06   \n",
       "692  UCYi4JJcjDYtNGLX0N6e7g5A   Men's Health & Fitness Tips  2015-07-15   \n",
       "693  UCLDw7ummSJnILbMZn2Azf2g                  ON THE RADAR  2011-12-04   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "687  Wellness y fitness evolucionado. Videos para m...  Fitness   \n",
       "688  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "689  Salut à tous je suis Batman fitness de la vérité.  Fitness   \n",
       "692  Men Health & Fitness and Sexual Tips , This Ch...  Fitness   \n",
       "693  ON THE RADAR IS YOUR ULTIMATE RESOURCE FOR Hea...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "687            440108        595.545332          739    39335272   \n",
       "688               170          0.242511          701      104568   \n",
       "689               891          1.265625          704      216151   \n",
       "692             95118        162.040886          587    18476925   \n",
       "693             56812         99.321678          572    12849332   \n",
       "\n",
       "     Views/Subscriber   Views/Video  Comments/Upload  Comments/View  \\\n",
       "687         89.376408  53227.702300             6.82       0.100957   \n",
       "688        615.105882    149.169757             0.00       0.000000   \n",
       "689        242.593715    307.032670            14.58       6.234693   \n",
       "692        194.252665  31476.873935             4.44       0.158249   \n",
       "693        226.172851  22463.867133            28.80       1.893966   \n",
       "\n",
       "     Days/Upload  Dislikes/Upload  Dislikes/View  Growth Rate  Likes/Upload  \\\n",
       "687          1.2             5.96       0.093251    -1.067616        465.14   \n",
       "688          5.0             0.00       0.000000     0.107155          0.14   \n",
       "689          0.3             5.06       2.180904    -6.571514         15.96   \n",
       "692          1.3            15.44       0.175641  -591.460505        290.94   \n",
       "693          6.2             4.86       0.342653    -1.409487        151.20   \n",
       "\n",
       "     Likes/View  Views/Upload  \n",
       "687    7.216093       6642.84  \n",
       "688    0.273421         47.76  \n",
       "689    7.857068        253.56  \n",
       "692    2.322659      20110.36  \n",
       "693    6.117708       5736.02  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Channels with no videos returned are filtered out (ex: UCOpNcN46UbXVtpKMrmU4Abg)\n",
    "\n",
    "def extend_video_features(data):\n",
    "    extended_video = { 'Channel ID': [] }\n",
    "        \n",
    "    for channel_id in data['Channel ID']:            \n",
    "        channel_video_stats = get_channel_video_stats(channel_id)\n",
    "        \n",
    "        if channel_video_stats == None:\n",
    "            continue\n",
    "                    \n",
    "        extended_video['Channel ID'].append(channel_id)\n",
    "        for video_stat in channel_video_stats:\n",
    "            if video_stat not in extended_video:\n",
    "                extended_video[video_stat] = []\n",
    "            extended_video[video_stat].append(channel_video_stats[video_stat])\n",
    "                                        \n",
    "    extended_dataset = pd.DataFrame.from_dict(extended_video).set_index('Channel ID')\n",
    "    \n",
    "    return data.join(extended_dataset, on=\"Channel ID\", how=\"inner\")\n",
    "\n",
    "dataset = extend_video_features(channel_features_dataset)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "\n",
    "We now have 15 features on 700 channels on its most recent 50 videos that we'll store in a csv file \"youtube-data.csv\", and we're ready to extract the important features and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('youtube-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our assembled dataset, we need to apply some normalization methods to ensure that our KMeans++ clustering can give us the most meaningful results possible. To do so, we will apply feature scaling to bring the variance of our clusters closer together and apply kernel PCA as well to increase the dimensionality of our data so PCA can identify non-linear principal components.\n",
    "\n",
    "#### Feature Normalization\n",
    "On of the most common ways to standardize data across a dimension is to reduce the dimension to zero mean and unit variance. Let's apply the formula below for each feature dimension and see how our data changes. \n",
    "\n",
    "<center>$X^{(m)} = \\frac{X^{(m)} - \\overline{X^{(m)}}}{\\sigma}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "      <th>Comments/Upload</th>\n",
       "      <th>Comments/View</th>\n",
       "      <th>Days/Upload</th>\n",
       "      <th>Dislikes/Upload</th>\n",
       "      <th>Dislikes/View</th>\n",
       "      <th>Growth Rate</th>\n",
       "      <th>Likes/Upload</th>\n",
       "      <th>Likes/View</th>\n",
       "      <th>Views/Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>UCjKr2Ro-5X0BM6UptvhWvEw</td>\n",
       "      <td>The Ultimate Fashion History</td>\n",
       "      <td>10/26/12</td>\n",
       "      <td>FASHION HISTORY LIKE YOU'VE NEVER LEARNED IT B...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.431295</td>\n",
       "      <td>-0.341956</td>\n",
       "      <td>-0.448291</td>\n",
       "      <td>-0.311062</td>\n",
       "      <td>-0.629982</td>\n",
       "      <td>-0.311746</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>-0.234135</td>\n",
       "      <td>-0.253131</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>-0.326700</td>\n",
       "      <td>0.398713</td>\n",
       "      <td>-0.236878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>UCS-HyxHT3A_PLXC8zlX73Yw</td>\n",
       "      <td>Fashion Television</td>\n",
       "      <td>11/10/14</td>\n",
       "      <td>Fashion Television is considered the leading a...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.435253</td>\n",
       "      <td>-0.363157</td>\n",
       "      <td>-0.143750</td>\n",
       "      <td>-0.306632</td>\n",
       "      <td>0.783178</td>\n",
       "      <td>-0.318565</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.597007</td>\n",
       "      <td>-0.235434</td>\n",
       "      <td>-0.287314</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>-0.331377</td>\n",
       "      <td>-0.922151</td>\n",
       "      <td>-0.239402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>UCoc8tpGCY1wrp8pV7mI0scA</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>3/7/07</td>\n",
       "      <td>Welcome to H&amp;M's official YouTube page. Explor...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.294380</td>\n",
       "      <td>-0.270066</td>\n",
       "      <td>-0.286767</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>1.182617</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>0.367722</td>\n",
       "      <td>-0.065151</td>\n",
       "      <td>-0.105284</td>\n",
       "      <td>0.475871</td>\n",
       "      <td>-0.289295</td>\n",
       "      <td>-1.015866</td>\n",
       "      <td>0.880160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>UCkkVe_1wVVhT_w_BU6CKgXw</td>\n",
       "      <td>Fashion9tv</td>\n",
       "      <td>8/10/16</td>\n",
       "      <td>fashion9tv channel is reference channel for ge...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>-0.416403</td>\n",
       "      <td>-0.362802</td>\n",
       "      <td>1.041181</td>\n",
       "      <td>-0.286283</td>\n",
       "      <td>0.387297</td>\n",
       "      <td>-0.318919</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.708859</td>\n",
       "      <td>-0.235288</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>-0.010982</td>\n",
       "      <td>-0.331367</td>\n",
       "      <td>-1.258717</td>\n",
       "      <td>-0.239284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>UCPlqUggohC1vldNi3biHkvA</td>\n",
       "      <td>Fitness Incentive</td>\n",
       "      <td>10/18/10</td>\n",
       "      <td>Watch, learn and enjoy Fitness incentive instr...</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>-0.439641</td>\n",
       "      <td>-0.364862</td>\n",
       "      <td>-0.204322</td>\n",
       "      <td>-0.313200</td>\n",
       "      <td>1.446982</td>\n",
       "      <td>-0.323333</td>\n",
       "      <td>-0.272409</td>\n",
       "      <td>-0.563164</td>\n",
       "      <td>-0.051725</td>\n",
       "      <td>-0.235467</td>\n",
       "      <td>-0.414546</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>-0.331404</td>\n",
       "      <td>-1.356894</td>\n",
       "      <td>-0.239401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Channel ID                  Channel Name   Created  \\\n",
       "604  UCjKr2Ro-5X0BM6UptvhWvEw  The Ultimate Fashion History  10/26/12   \n",
       "605  UCS-HyxHT3A_PLXC8zlX73Yw            Fashion Television  11/10/14   \n",
       "606  UCoc8tpGCY1wrp8pV7mI0scA                           H&M    3/7/07   \n",
       "607  UCkkVe_1wVVhT_w_BU6CKgXw                    Fashion9tv   8/10/16   \n",
       "608  UCPlqUggohC1vldNi3biHkvA             Fitness Incentive  10/18/10   \n",
       "\n",
       "                                           Description    Genre  \\\n",
       "604  FASHION HISTORY LIKE YOU'VE NEVER LEARNED IT B...  Fashion   \n",
       "605  Fashion Television is considered the leading a...  Fashion   \n",
       "606  Welcome to H&M's official YouTube page. Explor...  Fashion   \n",
       "607  fashion9tv channel is reference channel for ge...  Fashion   \n",
       "608  Watch, learn and enjoy Fitness incentive instr...  Fitness   \n",
       "\n",
       "     Subscriber Count  Subscriber/Video  Video Count  View Count  \\\n",
       "604         -0.431295         -0.341956    -0.448291   -0.311062   \n",
       "605         -0.435253         -0.363157    -0.143750   -0.306632   \n",
       "606         -0.294380         -0.270066    -0.286767   -0.043644   \n",
       "607         -0.416403         -0.362802     1.041181   -0.286283   \n",
       "608         -0.439641         -0.364862    -0.204322   -0.313200   \n",
       "\n",
       "     Views/Subscriber  Views/Video  Comments/Upload  Comments/View  \\\n",
       "604         -0.629982    -0.311746        -0.272409      -0.563164   \n",
       "605          0.783178    -0.318565        -0.272409      -0.563164   \n",
       "606          1.182617     0.005803        -0.272409      -0.563164   \n",
       "607          0.387297    -0.318919        -0.272409      -0.563164   \n",
       "608          1.446982    -0.323333        -0.272409      -0.563164   \n",
       "\n",
       "     Days/Upload  Dislikes/Upload  Dislikes/View  Growth Rate  Likes/Upload  \\\n",
       "604     0.144017        -0.234135      -0.253131    -0.004679     -0.326700   \n",
       "605    -0.597007        -0.235434      -0.287314     0.001706     -0.331377   \n",
       "606     0.367722        -0.065151      -0.105284     0.475871     -0.289295   \n",
       "607    -0.708859        -0.235288       0.016218    -0.010982     -0.331367   \n",
       "608    -0.051725        -0.235467      -0.414546     0.002601     -0.331404   \n",
       "\n",
       "     Likes/View  Views/Upload  \n",
       "604    0.398713     -0.236878  \n",
       "605   -0.922151     -0.239402  \n",
       "606   -1.015866      0.880160  \n",
       "607   -1.258717     -0.239284  \n",
       "608   -1.356894     -0.239401  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data = pd.read_csv('youtube-data.csv')\n",
    "\n",
    "dataset = orig_data.drop(['Unnamed: 0'], axis=1)\n",
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "dataset = dataset.dropna(axis=0, how=\"any\")\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "def standardize_features(X):\n",
    "    return (X - np.mean(X)) / np.std(X)\n",
    "\n",
    "def normalize_data(data):\n",
    "    result = data.copy(deep=True)\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == object:\n",
    "            continue\n",
    "        result[column] = standardize_features(data[column])\n",
    "    return result\n",
    "\n",
    "norm_dataset = normalize_data(dataset)\n",
    "norm_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel PCA\n",
    "\n",
    "Next, we will apply a Gaussian RBF (Radial Basis Function) kernel to map our data into a higher dimensional space so we can identify a potentially non-linear lower dimensional subspace for our principal components. This is done by applying the function below to each pair of feature vectors.\n",
    "\n",
    "<center>$K(x,y) = exp(-\\frac{||x-y||^2}{2\\sigma^2})$</center>\n",
    "\n",
    "Additionally, we'll also apply a median distance trick and use that as the standard deviation across our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calc_median_dist(X):\n",
    "    dists = []\n",
    "    n,m = X.shape\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dist = np.sqrt(np.sum((X[i,:]-X[j,:])**2))\n",
    "            dists.append(dist)\n",
    "    return np.median(dists)\n",
    "\n",
    "def drop_non_numerical(data):\n",
    "    drop_cols = []\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == object:\n",
    "            drop_cols.append(column)\n",
    "    return data.drop(drop_cols, axis=1)\n",
    "\n",
    "def kernel_PCA(data, n=6):\n",
    "    num_data = drop_non_numerical(data)\n",
    "    num_data = num_data.as_matrix()\n",
    "    \n",
    "    median_dist = calc_median_dist(num_data)\n",
    "    gamma = 1/(2*median_dist**2)\n",
    "    rbf = np.exp(-gamma * (np.sum(num_data**2, axis=-1)[:,None] + np.sum(num_data**2, axis=-1)[None,:] - 2*np.dot(num_data, num_data.T)))\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca.fit_transform(rbf)\n",
    "    \n",
    "kernel_data = kernel_PCA(norm_dataset)\n",
    "print(kernel_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have transformed our dataset into several potentially non-linear principal components, we will train a clustering model to see what major clusters these channels form.\n",
    "\n",
    "For this part, we chose the KMeans++ model because we think that similar channels (popular, growing, declining) should be close in distance in the project feature space (ie. share similar properties based on these identified metrics). In addition, we initially choose to train on $k=4$ clusters because we wanted an additional bucket for channels we cannot successfully label as one of our 3 types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From dzq homework 5\n",
    "import math\n",
    "\n",
    "def distance_matrix(X):\n",
    "    m,n = X.shape\n",
    "    M = np.zeros((m,m))\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            M[i,j] = np.sum((X[i]-X[j])**2)\n",
    "    return M\n",
    "\n",
    "class KMeans:\n",
    "    def init_centers(self, X, k):\n",
    "        centers = []\n",
    "        m = X.shape[0]\n",
    "        M = distance_matrix(X)\n",
    "        pos = np.arange(len(X))\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                center = X[np.random.choice(pos)]\n",
    "            else:\n",
    "                # Calculate probabilities\n",
    "                probs = []\n",
    "                for x in range(m):\n",
    "                    # Calculate each vector's probability\n",
    "                    sub_probs = []\n",
    "                    for y in range(m):\n",
    "                        sub_prob = []\n",
    "                        for center in centers:\n",
    "                            dist_to_center = np.sum((X[y]-center)**2)\n",
    "                            sub_prob.append(dist_to_center)\n",
    "                        val = np.min(sub_prob)\n",
    "                        sub_probs.append(val)\n",
    "                    \n",
    "                    num = sub_probs[x]\n",
    "                    denom = np.sum(sub_probs)\n",
    "                    \n",
    "                    prob = num/denom\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "                center = X[np.random.choice(pos, p=probs)]\n",
    "                \n",
    "            centers.append(center)\n",
    "            \n",
    "        centers = np.array(centers)\n",
    "        return centers\n",
    "        \n",
    "    def assign_clusters(self, X, centers):\n",
    "        m,k = X.shape[0], len(centers) \n",
    "        clusters = np.zeros((m,k))\n",
    "        for i in range(m):\n",
    "            probs = []\n",
    "            for j in range(k):\n",
    "                dist = np.sum((X[i]-centers[j])**2)\n",
    "                probs.append(dist)\n",
    "            y = np.argmin(probs)\n",
    "            clusters[i,y] = 1\n",
    "        return clusters\n",
    "    \n",
    "    def compute_means(self, X, y):\n",
    "        m, n, k = X.shape[0], X.shape[1], y.shape[1]\n",
    "        centers = np.zeros((k,n))\n",
    "        \n",
    "        for j in range(k):\n",
    "            cluster = np.zeros(n)\n",
    "            num_cluster = 0\n",
    "            for i in range(m):\n",
    "                if y[i,j] == 1:\n",
    "                    num_cluster += 1\n",
    "                    cluster = cluster + X[i]\n",
    "            center = cluster / num_cluster\n",
    "            centers[j,:] = center\n",
    "            \n",
    "        return centers    \n",
    "    \n",
    "    def train(self, X, centers, niters=500):\n",
    "        for i in range(niters):\n",
    "            clusters = self.assign_clusters(X, centers)\n",
    "            centers = self.compute_means(X, clusters)\n",
    "                    \n",
    "        return (clusters, centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running KMeans++, we can see the size of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  364\n",
      "Cluster 1:  58\n",
      "Cluster 2:  85\n",
      "Cluster 3:  102\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "KM = KMeans()\n",
    "mu = KM.init_centers(kernel_data, k)\n",
    "(labels, centers) = KM.train(kernel_data, mu)\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d: \" % i, len(np.where(labels[:,i]==1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what channels are in our largest cluster, cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57                                    Adam Saleh Fashion\n",
       "66                                       RawBeautyKristi\n",
       "70                                       Fashion Diaries\n",
       "72                                    Inner Beauty Bybel\n",
       "74                                  The Life Of Us Vlogs\n",
       "76                                     TheGamingBritShow\n",
       "79                                      Gaming Historian\n",
       "82                                          ilie's vlogs\n",
       "83                            Best Ever Food Review Show\n",
       "84                                        Sascha Fitness\n",
       "87                                     Britpoplife Vlogs\n",
       "96                                       Laura Lee Vlogs\n",
       "97                                             UIC Vlogs\n",
       "100                        ERNEST DIFT - THE FITNESS BOY\n",
       "104                                               Anil B\n",
       "117                                    Samantha Ravndahl\n",
       "125                                            Lù Gaming\n",
       "130                                     The Food Emperor\n",
       "133                                    VitruvianPhysique\n",
       "135                                         Dobbs Gaming\n",
       "139                                        Fashion Laura\n",
       "140                             Justine Leconte officiel\n",
       "143                                       Vlog Creations\n",
       "145                                           다영 DAYEONG\n",
       "147                                              BenDeen\n",
       "154                                      Thefoodreviewer\n",
       "155                                        Nassim Sahili\n",
       "157                               Linkin Simpson's vlogs\n",
       "159                                    HappyConsoleGamer\n",
       "162                                        Beauty Tricks\n",
       "                             ...                        \n",
       "577                                          Gaming Blog\n",
       "578                                           Fitness.ee\n",
       "579                                         Time Fitness\n",
       "580                                     The Food Channel\n",
       "581                  WILLITARY FITNESS! FIT FUN AT HOME!\n",
       "582                                    BARÁTOK Blog Vlog\n",
       "583                              British Fashion Council\n",
       "584                              Fashion And Accessories\n",
       "585                                  U.S. Forces Fitness\n",
       "586                                       Gorilla Gaming\n",
       "587                          Style and fashion by bassem\n",
       "588                               Moda 2017 Fashion 2018\n",
       "589                                   Lakmé Fashion Week\n",
       "591                                            HW Beauty\n",
       "592                                      Beauty at Tesco\n",
       "593                               Latest Fashion Designs\n",
       "594                                     iOS Gaming World\n",
       "595                                          Fashion One\n",
       "596                                     Heath and Beauty\n",
       "597                                    Fly Dance Fitness\n",
       "598                              Premier Fitness Systems\n",
       "599                                 GU | Gaming-Universe\n",
       "600                                Princess Fashion Show\n",
       "601                                        ID Fashion TV\n",
       "602                                         Steves vlogs\n",
       "603    Food and Agriculture Organization of the Unite...\n",
       "604                         The Ultimate Fashion History\n",
       "605                                   Fashion Television\n",
       "607                                           Fashion9tv\n",
       "608                                    Fitness Incentive\n",
       "Name: Channel Name, Length: 364, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Channel Name\"][labels[:,0] == 1] # Cluster 0 (364 channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters\n",
    "\n",
    "In this section, we will consider $k$ that will generate different cluster labels for each channel. Then, we will calculate an error using cross entropy on a curated test dataset and minimize this our objective funciton to obtain the optimal hyperparameter.\n",
    "\n",
    "#### Test Data\n",
    "\n",
    "Our test dataset was manually assembled by searching for popular YouTube channels online, and filtering for channels that are not already in our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel ID</th>\n",
       "      <th>Subscriber Count</th>\n",
       "      <th>Subscriber/Video</th>\n",
       "      <th>Video Count</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Views/Subscriber</th>\n",
       "      <th>Views/Video</th>\n",
       "      <th>Comments/Upload</th>\n",
       "      <th>Comments/View</th>\n",
       "      <th>Days/Upload</th>\n",
       "      <th>Dislikes/Upload</th>\n",
       "      <th>Dislikes/View</th>\n",
       "      <th>Growth Rate</th>\n",
       "      <th>Likes/Upload</th>\n",
       "      <th>Likes/View</th>\n",
       "      <th>Views/Upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UCXIJ2-RSIGn53HA-x9RDevA</td>\n",
       "      <td>769319</td>\n",
       "      <td>507.466359</td>\n",
       "      <td>1516</td>\n",
       "      <td>110327335</td>\n",
       "      <td>143.409086</td>\n",
       "      <td>72775.286939</td>\n",
       "      <td>134.10</td>\n",
       "      <td>0.544479</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>-0.300257</td>\n",
       "      <td>953.90</td>\n",
       "      <td>3.390158</td>\n",
       "      <td>33301.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UCuA6Ht35K326kBTPTXaWj3g</td>\n",
       "      <td>36234</td>\n",
       "      <td>175.043478</td>\n",
       "      <td>207</td>\n",
       "      <td>1875574</td>\n",
       "      <td>51.762819</td>\n",
       "      <td>9060.743961</td>\n",
       "      <td>36.78</td>\n",
       "      <td>0.694202</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.055365</td>\n",
       "      <td>-0.083422</td>\n",
       "      <td>225.40</td>\n",
       "      <td>4.535455</td>\n",
       "      <td>5013.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UCgBc9iNvvjWDInV6fBeTGXQ</td>\n",
       "      <td>389117</td>\n",
       "      <td>769.005929</td>\n",
       "      <td>506</td>\n",
       "      <td>87340230</td>\n",
       "      <td>224.457502</td>\n",
       "      <td>172609.150198</td>\n",
       "      <td>167.12</td>\n",
       "      <td>0.308340</td>\n",
       "      <td>10.5</td>\n",
       "      <td>46.06</td>\n",
       "      <td>0.098512</td>\n",
       "      <td>-0.160174</td>\n",
       "      <td>1519.96</td>\n",
       "      <td>3.093674</td>\n",
       "      <td>54365.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UCuY1W4AwhhgkB6rsJBtltUA</td>\n",
       "      <td>919382</td>\n",
       "      <td>535.146682</td>\n",
       "      <td>1718</td>\n",
       "      <td>422337654</td>\n",
       "      <td>459.371245</td>\n",
       "      <td>245830.997672</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.104523</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.083028</td>\n",
       "      <td>-0.159771</td>\n",
       "      <td>65.04</td>\n",
       "      <td>2.220566</td>\n",
       "      <td>3380.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UCMTXToEZ6VT5k9GOCFNYjWA</td>\n",
       "      <td>82842</td>\n",
       "      <td>236.017094</td>\n",
       "      <td>351</td>\n",
       "      <td>6557259</td>\n",
       "      <td>79.153799</td>\n",
       "      <td>18681.649573</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2580.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Channel ID  Subscriber Count  Subscriber/Video  Video Count  \\\n",
       "20  UCXIJ2-RSIGn53HA-x9RDevA            769319        507.466359         1516   \n",
       "21  UCuA6Ht35K326kBTPTXaWj3g             36234        175.043478          207   \n",
       "22  UCgBc9iNvvjWDInV6fBeTGXQ            389117        769.005929          506   \n",
       "23  UCuY1W4AwhhgkB6rsJBtltUA            919382        535.146682         1718   \n",
       "24  UCMTXToEZ6VT5k9GOCFNYjWA             82842        236.017094          351   \n",
       "\n",
       "    View Count  Views/Subscriber    Views/Video  Comments/Upload  \\\n",
       "20   110327335        143.409086   72775.286939           134.10   \n",
       "21     1875574         51.762819    9060.743961            36.78   \n",
       "22    87340230        224.457502  172609.150198           167.12   \n",
       "23   422337654        459.371245  245830.997672             3.12   \n",
       "24     6557259         79.153799   18681.649573             5.72   \n",
       "\n",
       "    Comments/View  Days/Upload  Dislikes/Upload  Dislikes/View  Growth Rate  \\\n",
       "20       0.544479          3.9            13.12       0.051596    -0.300257   \n",
       "21       0.694202         22.2             1.88       0.055365    -0.083422   \n",
       "22       0.308340         10.5            46.06       0.098512    -0.160174   \n",
       "23       0.104523          7.3             2.84       0.083028    -0.159771   \n",
       "24       0.434921         12.4             0.00       0.000000     0.262021   \n",
       "\n",
       "    Likes/Upload  Likes/View  Views/Upload  \n",
       "20        953.90    3.390158      33301.62  \n",
       "21        225.40    4.535455       5013.08  \n",
       "22       1519.96    3.093674      54365.50  \n",
       "23         65.04    2.220566       3380.58  \n",
       "24          0.00    0.000000       2580.64  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_channel_ids = {\n",
    "    \"Vlog\": [\n",
    "        \"UC4-CH0epzZpD_ARhxCx6LaQ\",\n",
    "        \"UC_gV70G_Y51LTa3qhu8KiEA\",\n",
    "        \"UCcgVECVN4OKV6DH1jLkqmcA\",\n",
    "        \"UCPOw2O3_uZ1doro9iR4x6vw\",\n",
    "        \"UC0otZdGYsA9KqVKAcn2peQA\"\n",
    "    ], \"Food\": [\n",
    "        \"UCJQL1Fai-9GlVunsbP4x8Pg\",\n",
    "        \"UCRIZtPl9nb9RiXc9btSTQNw\",\n",
    "        \"UCNbngWUqL2eqRw12yAwcICg\",\n",
    "        \"UC6S5a3MQtr_PSWZxysXkOCg\",\n",
    "        \"UCffs63OaN2nh-6StR6hzfiQ\"\n",
    "    ], \"Gaming\": [\n",
    "        \"UCAW-NpUFkMyCNrvRSSGIvDQ\",\n",
    "        \"UC1uvf8YdxSVzthF45kotmJQ\",\n",
    "        \"UCbTVTephX30ZhQF5zwFppBg\",\n",
    "        \"UCS5Oz6CHmeoF7vSad0qqXfw\",\n",
    "        \"UCpGdL9Sn3Q5YWUH2DVUW1Ug\"\n",
    "    ], \"Fashion\": [\n",
    "        \"UC5zSySQab9SA6Wz569WDgqw\",\n",
    "        \"UCgWfS_47YPVbKx5EK4FLm4A\",\n",
    "        \"UCo5zIpjl2OQkYatd8R0bDaw\",\n",
    "        \"UC-BaXc1TU9i0XSguq9mZwdg\",\n",
    "        \"UC48DOiEvCDu3sThBijwkQ1A\"\n",
    "    ], \"Fitness\": [\n",
    "        \"UCXIJ2-RSIGn53HA-x9RDevA\",\n",
    "        \"UCuA6Ht35K326kBTPTXaWj3g\",\n",
    "        \"UCgBc9iNvvjWDInV6fBeTGXQ\",\n",
    "        \"UCuY1W4AwhhgkB6rsJBtltUA\",\n",
    "        \"UCMTXToEZ6VT5k9GOCFNYjWA\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_test_dataset(channel_ids):\n",
    "    test_dataset = { \"Channel ID\": [] }\n",
    "    for topic in channel_ids:\n",
    "        for channel_id in test_channel_ids[topic]:\n",
    "            test_dataset[\"Channel ID\"].append(channel_id)\n",
    "    \n",
    "    test_data = pd.DataFrame.from_dict(test_dataset)\n",
    "    init_test = extend_features(test_data)\n",
    "    return extend_video_features(init_test)\n",
    "            \n",
    "test_data = create_test_dataset(test_channel_ids)\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's save this into a spreadsheet for easy loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv('youtube-test-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we apply the same cleaning and feature space transformations onto our test data we can calculate distances to the training data cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 6)\n"
     ]
    }
   ],
   "source": [
    "orig_test = pd.read_csv('youtube-test-data.csv')\n",
    "\n",
    "test_data = orig_test.drop(['Unnamed: 0'], axis=1)\n",
    "test_data = orig_test.replace([np.inf, -np.inf], np.nan)\n",
    "test_data = test_data.dropna(axis=0, how=\"any\")\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "test_norm = normalize_data(test_data)\n",
    "test_kernel = kernel_PCA(test_norm)\n",
    "print(test_kernel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss\n",
    "\n",
    "Since these channels are very similar and commonly recognized as popular channels on YouTube, we will asumme that they should be classified into similar clusters under our model. Thus, we can use the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def cross_entropy(cluster_labels):\n",
    "    freqs = Counter()\n",
    "    for label in cluster_labels:\n",
    "        freqs[label] += 1\n",
    "        \n",
    "    n = len(cluster_labels)\n",
    "    entropy = 0\n",
    "    for label in freqs:\n",
    "        label_prob = freqs[label]/n\n",
    "        entropy += label_prob*np.log(label_prob)\n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a model testing function that returns the total entropy for a given model and another wrapper function that minimize cross entropy loss across models trained on different hyperparameter $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3  error=0.6792\n",
      "k=4  error=1.0240\n",
      "k=5  error=0.2868\n",
      "k=6  error=0.2868\n",
      "k=7  error=0.6520\n"
     ]
    }
   ],
   "source": [
    "def test_model(KM, centers, test_data):\n",
    "    predicted_clusters = KM.assign_clusters(test_data, centers)    \n",
    "    predicted_labels = list(map(lambda x: np.argmax(x), predicted_clusters))\n",
    "    return cross_entropy(predicted_labels)\n",
    "\n",
    "def optimize(train_data, test_data):\n",
    "    min_error = None\n",
    "    opt_k = None\n",
    "    opt_model = None\n",
    "    opt_centers = None\n",
    "    opt_labels = None\n",
    "    \n",
    "    for k in range(3,8): # 3,4,5,6,7\n",
    "        kmeans = KMeans()\n",
    "        init_centers = kmeans.init_centers(train_data, k)\n",
    "        labels, centers = kmeans.train(train_data, init_centers)\n",
    "        \n",
    "        error = test_model(kmeans, centers, test_data)\n",
    "        \n",
    "        print(\"k=%d  error=%0.4f\" % (k,error))\n",
    "        \n",
    "        if min_error == None or error < min_error:\n",
    "            min_error = error\n",
    "            opt_k = k\n",
    "            opt_model = kmeans\n",
    "            opt_centers = centers\n",
    "            opt_labels = labels\n",
    "            \n",
    "    return (opt_k, opt_model, opt_centers, opt_labels)\n",
    "        \n",
    "k, KM, opt_centers, opt_labels = optimize(kernel_data, test_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information about our optimal hyperparameter, we can train a new KMeans++ model with $k=5$ and use that to visualize the clusters we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Visualization\n",
    "\n",
    "We use plotly in our cluster visualization because it supports powerful interactive graphs, and we are visualizing the assigned labels on our training data in the first 3 principal components. The plot generated can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pdsfinal/0 or inside your plot.ly account where it is named 'cluster-3d-scatter'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pdsfinal/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username=\"pdsfinal\", api_key=\"uWfUSo3kfMnXM6gTxmUO\")\n",
    "\n",
    "def visualize_clusters_3D(data, labels, k):\n",
    "    transformed = data[:, 0:3]\n",
    "    \n",
    "    plot_data = []\n",
    "    for i in range(k):\n",
    "        trace = go.Scatter3d(\n",
    "            x=transformed[np.where(labels[:,i] == 1)[0]][:,0],\n",
    "            y=transformed[np.where(labels[:,i] == 1)[0]][:,1],\n",
    "            z=transformed[np.where(labels[:,i] == 1)[0]][:,2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=12,\n",
    "                line=dict(\n",
    "                    color='rgba(217,217,217,0.14)',\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "        plot_data.append(trace)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "    return go.Figure(data=plot_data, layout=layout)\n",
    "    \n",
    "fig = visualize_clusters_3D(kernel_data, opt_labels, k)\n",
    "py.iplot(fig, filename='cluster-3d-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, now that we have labeled data, we can visualize the clusters with respect to our original features. We will explore clusters with regards to some of those metrics below.\n",
    "\n",
    "First, we'll get the dataframe indices for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_idxs(labels, k):\n",
    "    cluster_idxs = dict()\n",
    "    for i in range(k):\n",
    "        cluster_idxs[i] = np.where(labels[:,i] == 1)[0]\n",
    "    return cluster_idxs\n",
    "\n",
    "cluster_idxs = get_cluster_idxs(opt_labels, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since PCA transforms our data by projecting each feature to the principal components, the $x,y,z$ axes in the plot above don't necessarily correspond to our original features in the way we would expect it. However, we can use the clusters that our KMeans++ model has identified to visualize features we've identified earlier.\n",
    "\n",
    "Here's an example of that with subscriber count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pdsfinal/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_cluster_stacked_histogram(data, feature, clusters, labels, k):      \n",
    "    plot_data = []\n",
    "    for i in range(k):\n",
    "        trace = go.Histogram(\n",
    "            x = dataset[feature][clusters[i]],\n",
    "            name = \"Cluster %d\" % i\n",
    "        )\n",
    "        plot_data.append(trace)\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(title=feature),\n",
    "        yaxis=dict(title=\"Count\"),\n",
    "        barmode=\"stack\")\n",
    "    \n",
    "    return go.Figure(data=plot_data, layout=layout)\n",
    "    \n",
    "fig = visualize_cluster_stacked_bar_chart(dataset, \"Subscriber Count\", cluster_idxs, opt_labels, k)\n",
    "py.iplot(fig, filename='cluster-subscriber-count-stacked-histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another one with upload frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pdsfinal/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = visualize_cluster_stacked_histogram(dataset, \"Days/Upload\", cluster_idxs, opt_labels, k)\n",
    "py.iplot(fig, filename='cluster-days-upload-stacked-histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked histograms are pretty cool, but you can tell that they're skewed towards representing cluster 0 because that's our largest cluster. \n",
    "\n",
    "However, there are certain insights we've gained from visualizing the data. In the upload frequency plot above, we can see that channels from cluster 1 and 4 tend to be really frequent uploaders (videos within a day).\n",
    "\n",
    "### Cluster Types\n",
    "\n",
    "(Amy pls do this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future Directions\n",
    "\n",
    "1. Analyzing genres separately\n",
    "2. Webscraping for smaller channels\n",
    "3. Create time series database\n",
    "4. Exploring other unsupervised clustering algorithms\n",
    "5. Training sentiment analysis model\n",
    "\n",
    "In this project we failed to consider the differences between what makes a channel successful across different genres, so in the future we look to analyze each genre separately to reduce the effects of any confounding variables across genres.\n",
    "\n",
    "When we queried the YouTube Data API, it was inherently biased towards larger channels because they sorted in descending order on the metrics we specified in our parameters. Because of this, it might be good to webscrape for smaller channels and look for which cluster our model would assign them to.\n",
    "\n",
    "Another interesting idea is to query the database more consistently. Then, we can start assembling our own database with historical data on each channel, which can be much more useful to characterize the growth, for example, of a channel. This is most likely what SocialBlade, a YouTube analytics platform, utilizes.\n",
    "\n",
    "Although KMeans++ is very easy to implement, the accuracy of its clusters relies on multiple assumptions about the dataset (spherically distributed clusters, similar variance across clusters, etc.). Thus, it could be beneficial to examine the performance of other clustering algorithms like GMM and hierarchical clustering to see what yields the lowest training and testing error.\n",
    "\n",
    "Lastly, in the beginning of this project we were initially interested in training a sentiment analysis model to analyze every channel's video captions and to use that as a feature in our model, but we ultimately decided against it because we found that captions across even one channel's videos were highly variable. Thus, we avoided it for the purposes of this project but that could be something else to look into when expanding on our feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count: 2037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
